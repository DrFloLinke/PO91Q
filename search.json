[{"path":"index.html","id":"preface","chapter":"Preface","heading":"Preface","text":"\n!!! site still construction !!!\nWelcome “Fundamentals Quantitative Research Methods”. module two main aims: introduce secondary data acquisition, management analysis social sciences; prepare attend statistical training make use statistics future research works, academic (master’s PhD dissertations) . module require prior knowledge mathematics statistics. need understand importance statistics empirical social sciences, show willingness learn .online companion seminars PO91Q. hosts material needed seminars replaces physical worksheets. environmentally friendlier, great advantage working R, allows copy/paste code directly code chunks online companion.hope find useful!","code":""},{"path":"companion-features.html","id":"companion-features","chapter":"Companion Features","heading":"Companion Features","text":"find embedded text six different types boxes serve different purposes:box appears whenever want stop particular point worksheet flag done.appears need careful coding R avoid problems.explanations hopefully make work webpage learning material easier.start working R week 5, recorded videos ease working program.brief question tests understanding previous material.definition encountered lecture.","code":""},{"path":"accessibility.html","id":"accessibility","chapter":"Accessibility","heading":"Accessibility","text":"companion uses font “Lexend”. Lexend fonts intended reduce visual stress improve reading performance. Initially designed dyslexia struggling readers mind, Bonnie Shaver-Troup, creator Lexend project, soon found fonts also great everyone else.Code displayed Recursive Mono. font’s characters share width clear legibility perfect alignment. particularly helpful use programming data-heavy design tasks, also allows creative possibilities display typography.companion also uses dark mode theme. many users, including neurodivergent individuals, dark mode can reduce eye strain enhance focus minimising visual overstimulation.","code":""},{"path":"introduction-to-r.html","id":"introduction-to-r","chapter":"Introduction to R","heading":"Introduction to R","text":"","code":""},{"path":"introduction-to-r.html","id":"installation","chapter":"Introduction to R","heading":"Installation","text":"Today start working R first step install program. Please follow instructions:Go https://cran.r-project.org/mirrors.html select server want download R. convention server nearest . Follow -screen instructions install program.Go https://rstudio.com/products/rstudio/download/ download RStudio Desktop free. Install program.Now open RStudio - need open R , operating RStudio.Whilst need install R RStudio, never working R directly. Instead, operating RStudio.","code":""},{"path":"introduction-to-r.html","id":"r---getting-started","chapter":"Introduction to R","heading":"R - Getting Started","text":"worksheet also presentations documents use module, using two different fonts:Font plain textA typewriter font R functions, values, etc.also regularly including “screenshots” operations R output. Whenever see , please replicate computer. start, let’s look RStudio . open programme, presented following screen:\nFigure 1: RStudio\n– now – three components . left hand-side see -called Console can enter commands, also results displayed. right hands side, see Workspace consists upper lower window. upper window three tabs . tab Environment provide list data sets loaded R, also objects values create (later). History tab, find history (know, thought ) commands used. can useful retrace steps. Connections tab can connect online sources. use tab.lower window, five tabs. Files find file structure computer. set working directory (moment), can also view files working directory gives good overview files need refer particular project. Plots tab display graphs producing. Packages form heart soul R make program powerful (, later). RStudio also Help function, rarely illuminating. usually search stuff online “stackexchange”, large community R users share knowledge solutions problems. won’t use last tab Viewer.Introduction R StudioIf can’t get enough delightful German accent, videos go respective components worksheet screen. first:","code":""},{"path":"introduction-to-r.html","id":"rscript","chapter":"Introduction to R","heading":"RScript","text":"read previous section carefully, noticed wrote can enter commands” Console. can, shouldn’t. using instead RScript. RScript list commands use project (essay, dissertation, article) calculate quantities interest, descriptive statistics form mean, median mode, produce graphs.One foundations scientific research “reproducibility”“, ”replicability”. means “sufficient information exists understand, evaluate, build upon prior work third party replicate results without additional information author.” King (1995, p. 444, emphasis removed) principle applies academia generally, understand person done , can pick work whether left , push boundaries knowledge . bit closer home, also relevant conducting quantitative research assessments. require submit RScript (“file” use Stata) now together actual essay. check done; data preparation often time-consuming part (soon discover), way gain recognition work. actually advantage, mere plagiarism check.creation RScript allow open raw data, running script, bring exactly left . saves saving data sets can take lot work. back script properly, also insurance losing work day assessment due.create RScript, click File \\(\\rightarrow\\) New File \\(\\rightarrow\\) RScript. fourth window opens, screen now look something like :\nFigure 2: RScript Window\ncan now write commands RScript, new line (now) means new command. want execute command, put cursor line command press “command” / “enter” simultaneoulsy Mac “Ctrl” / “Enter” Windows.precede line #, can write annotations , example explaining particular command. next sub-section.Figure 3 shows start RScript worksheet. prefer dark background, ’s easier eyes, especially work R long periods. can change settings : Tools \\(\\rightarrow\\) Global Options \\(\\rightarrow\\) Appearance \\(\\rightarrow\\) Twilight.\nFigure 3: Example RScript\nThemesIf copy paste following code chunks “Console” run one time, even themes1 choose :can also download Flo’s Dark Theme2 “add” bottom “Appearance” menu.Appearance","code":"\ninstall.packages(\n  \"rsthemes\",\n  repos = c(gadenbuie = 'https://gadenbuie.r-universe.dev', getOption(\"repos\"))\n)\nrsthemes::install_rsthemes()"},{"path":"introduction-to-r.html","id":"rscript-structure","chapter":"Introduction to R","heading":"RScript Structure","text":"Well, German, like things neat tidy, feel almost compelled discuss properly organise RScript. apart genetical dispositions, well-organised RScript also much spirit reproducibility. simply makes sense structure RScript way another researcher able easily read understand .First , commands include? introduce current girlfriend boyfriend, interest learning past relationships; worked . similar fashion, nobody wants read lines code irrelvant. include RScript commands produce output actually include essay article.stated precede line #, can write annotations . also useful way structure RScript, example exercise numbers, sections essay /article, different stages data preparation (due course).RScript Structure","code":""},{"path":"introduction-to-r.html","id":"first-steps-in-r","chapter":"Introduction to R","heading":"First Steps in R","text":"enough preliminary talk, let’s get started R. principle, can think R massive powerful calculator. use start . want know sum 5 3 , type (RScript, Console):press “command” / “enter” (“Ctrl” / “enter” Windows). everything follow, commands shown individual boxes. clipboard button right, can copy paste code RScript. output presented separate box directly underneath. clipboard button, R render result console run code. , including result, calculation look like :[1] indicates 8 first component result. case, one component, ’s superfluous really, soon encounter situations results can number different items.can copy code page clicking clipboard icon top-right hand corner. can paste RScript.fundamental component R objects. can define object way reversed arrow, can assign values, characters, functions . want assign sum 5 3 object called result, example, call3If now call object, R return value, 8.Make habit adding note underneath code chunk RScript (preceded #) translate code plain English. especially useful lengthy complex chunks.","code":"\n5+3\n5+3[1] 8\nresult <- 5+3\nresult[1] 8"},{"path":"introduction-to-r.html","id":"the-working-directory","chapter":"Introduction to R","heading":"The Working Directory","text":"imperative create suitable filing system organise materials modules. least folder called “University” similar, sub-folder module take.modules working R, need extend system little. created schematic mind Figure 4.\nFigure 4: Folder Structure\nsee sub-folder week module, folders divided lecture seminar turn. can place lecture seminar materials, respectively. Create system now PO11Q.R works -called Working Directories. can think drawers R takes everything needs conduct analysis (data set), puts everything produces (graph plots). R-specific drawer within seminar, create yet another sub-folder seminar folder, call something suitable, “PO11Q_Seminar_Week 1”. call “Working Directory”, many , rendering name completely meaningless. Save file EU.xlsx folder. Data taken European Comission (n.d.).Please set structure now. find using random folder desktop named “working directory” coming weeks, going implode! mean .Now need tell R use folder. know file structure computer can simply use setwd() command, enter path. example computer:don’t know file structure computer, can click Session \\(\\rightarrow\\) Set Working Directory \\(\\rightarrow\\) Choose Directory.Working Directory","code":"\nsetwd(\"~/Warwick/Modules/PO91Q/Seminars/Week 1/R Week 1\")"},{"path":"introduction-to-r.html","id":"r-packages","chapter":"Introduction to R","heading":"R Packages","text":"difficult overstate importance packages R. program number “base” functions enable user many different basic things, packages extensions allow pretty much anything everything software - one reasons love much. first package need use enable us load Excel sheet R. called readxl. can install package command install.packages() package name goes, wrapped quotation marks, brackets:can load package library library() command.close R end session, library reset. reopen R, load packages require . install .","code":"\ninstall.packages(\"readxl\")\nlibrary(readxl)"},{"path":"introduction-to-r.html","id":"saving","chapter":"Introduction to R","heading":"Saving","text":"Please now save RScript folder (working directory) raw data. R asks closing, need save workspace data, running RScript raw data bring precisely left .","code":""},{"path":"exercises.html","id":"exercises","chapter":"Exercises","heading":"Exercises","text":"","code":""},{"path":"exercises.html","id":"core-exercises","chapter":"Exercises","heading":"Core Exercises","text":"Execute following lines command. time try explain happening, using statistical terms slides textbooks. know another statistical software, spot commonalities differences R. Experiment variations make sure interpretations right.Download “European Social Survey” dataset https://www.europeansocialsurvey.org/data. need register receive confirmation email. Select round 9 (2018), SPSS version (.sav). Download also:\nquestionnaire\nvariable list\n“showcards”\nSource project instructions\nTake bit time make sure understand documents .Download “European Social Survey” dataset https://www.europeansocialsurvey.org/data. need register receive confirmation email. Select round 9 (2018), SPSS version (.sav). Download also:questionnairethe variable listthe “showcards”Source project instructionsTake bit time make sure understand documents .Can tell:\n() population(s) reference?\n() sample(s) composed?\ninterviewers reach respondents?\nmethod questionnaire administration?\nCan tell:() population(s) reference?() sample(s) composed?interviewers reach respondents?method questionnaire administration?can now pick left worksheet. Make sure created appropriate folder structure set working directory. Also ensure loaded foreign package.can now pick left worksheet. Make sure created appropriate folder structure set working directory. Also ensure loaded foreign package.Execute: table(cntry). uses make variable research?","code":"\na<-1\nclass(a)\na\nb<-2\nb\nc<-a+b\nc\nd<-2*c\nd\ne<-c(10,20,30)\nclass(e)\ne\ne*10\nf<-c(\"Small\",\"Medium\",\"Big\")\nclass(f)\nf\ne[1]\nf[3]\nmean(e)\nmean(f)\nsd(e)\n?sd\nexample(sd)\ng<-c(e,f)\ng\nh<-rbind(e,f)\ni<-cbind(e,f)\nclass(h)\nh[1,]\ni[,2]\nh[1,2]\nls()\nls.str()\nsetwd(\"~/Warwick/Modules/PO91Q/Seminars/Week 1/Worksheet\")\n# This is my WD\n\nlibrary(foreign)\n# Loads the package for importing data\n\nESS<-read.spss(\"ESS9e03.sav\",to.data.frame=TRUE,max.value.labels=10)\n    # Imports the SPSS data with the right R format\n    # (ignore Warning messages in red)\n    # ('to.data.frame' converts the SPSS dataset into an R dataset)\n    # ('use.missings=TRUE' means you do not classify the values\n    # coded as missing in SPSS as missing in R)\n\nattach(ESS)\nView(ESS)\n    # Compare with the SPSS view\n    # Can you sort the data?\n    # Can you filter the data?\n\nnrow(ESS)\nncol(ESS)\ndim(ESS)\nnames(ESS)\nstr(ESS)\nhead(ESS)\n    # Can you imagine what the 6 functions above are for?\n    # Afterwards, check your answers using '?function'\n    # to get the help file for each function."},{"path":"exercises.html","id":"going-further","chapter":"Exercises","heading":"Going Further","text":"ESS questionnaire, showcards variable list, identify questions :\nlanguages spoken respondent R\nR’s educational background\nR’s relationship politics\nmany questions topic can find?\nsuitable survey study three topics?ESS questionnaire, showcards variable list, identify questions :languages spoken respondent RR’s educational backgroundR’s relationship politicsHow many questions topic can find?\nsuitable survey study three topics?Select one three topics according interest. Select set three variables particular interest (called X, Y Z ). Make sure understand meaning X, Y Z.Select one three topics according interest. Select set three variables particular interest (called X, Y Z ). Make sure understand meaning X, Y Z.return?Download “British Social Attitudes” Survey 2016 UK Data service website. need register, validate registration email, indicate within academic course agree conditions.\nChoose .tab .sav format.\nOpen .tab dataset Excel save .xlsx file. Import R readxl package.\nImport SPSS file R (ESS)\nTry understand differences 3 softwares, respective advantages disadvantages. BSA compare ESS regarding three topics listed ?Download “British Social Attitudes” Survey 2016 UK Data service website. need register, validate registration email, indicate within academic course agree conditions.Choose .tab .sav format.Open .tab dataset Excel save .xlsx file. Import R readxl package.Import SPSS file R (ESS)Try understand differences 3 softwares, respective advantages disadvantages. BSA compare ESS regarding three topics listed ?Download World Values Study 7 Gesis: https://dbk.gesis.org/dbksearch/sdesc2.asp?=4804. Select relevant files. EVS compare ESS BSA regarding 3 topics ?Download World Values Study 7 Gesis: https://dbk.gesis.org/dbksearch/sdesc2.asp?=4804. Select relevant files. EVS compare ESS BSA regarding 3 topics ?","code":"\nX\nY\nZ\ntable(X)\nplot(X)"},{"path":"homework-for-week-2.html","id":"homework-for-week-2","chapter":"Homework for Week 2","heading":"Homework for Week 2","text":"Finish working worksheet.Add note underneath code chunk RScript (starting line #), translating code plain English. help learn vocabulary grammar R quicker. unsure individual functions mean, can find .csv file full list week underneath flashcards (see , example).Read required literature week 2. Work thoroughly chapters 7 8 Fogarty book make sure familiar relevant commands produce descriptive statistics graphs R.Work week’s flashcards familiarise relevant R functions.Find example NEW function apply R ensure works","code":""},{"path":"glossary.html","id":"glossary","chapter":"Glossary","heading":"Glossary","text":" \nTable 1: Glossary Week 1\n ","code":""},{"path":"flashcards.html","id":"flashcards","chapter":"Flashcards","heading":"Flashcards","text":"week onwards find flashcards help learn purpose R functions PO91Q. divided :New Functions week, containing functions encounter first timeAll Functions week, containing functions used particular weekAll Functions now, containing functions used module particular week.\ncan download .csv file containing functions descriptions underneath flashcard window.wish create flashcards, example, difficult--remember functions, written instructions go .\n\n \n","code":""},{"path":"data-manipulation-in-r.html","id":"data-manipulation-in-r","chapter":"Data Manipulation in R","heading":"Data Manipulation in R","text":"","code":""},{"path":"data-manipulation-in-r.html","id":"self-reflection-questions-group-work","chapter":"Data Manipulation in R","heading":"Self-Reflection Questions – Group Work","text":"good practice always use RScript, rather simply entering commands console R?Give example unordered factor variable ordered one.descriptive statistics useful?Give example situation need transform character variable factor variable.always create new variable, instead overwriting existing one?questions taken Reiche (forthcoming).Please stop don’t go beyond point compared notes answers.","code":""},{"path":"data-manipulation-in-r.html","id":"opening-your-data-set","chapter":"Data Manipulation in R","heading":"Opening your Data Set","text":"now ready open data set R - called “data frame”. , create new object EU, ask R read “Sheet 1”” Excel file “EU.xlsx” placed working directory earlierWe can now use data R!Loading Data SetPlease use “Import Dataset” button Environment, properly, manually. sometimes need set options importing data sets, “pointy, clicky” approach won’t able offer need.","code":"\nlibrary(readxl)\nEU <- read_excel(\"EU.xlsx\", sheet=\"Sheet1\")"},{"path":"data-manipulation-in-r.html","id":"viewing-the-data","chapter":"Data Manipulation in R","heading":"Viewing the Data","text":"Unless cheeky opened file Excel look, idea yet, data look like. ’s good idea view data frame anything . can use View() command see data frame:want see first 6 observations variable, use head() command:simply want know variable names data frame, type:next one important command, reveals variable names first observations, also nature variable (numerical, character, etc.). str() command, “str” stands structure:can see R recognised variables numerical, one displayed character variable. appropriate variables, pop18, ordinal variable access ordinal. need recode , variables unhappy .","code":"\nView(EU)\nhead(EU)# A tibble: 6 × 5\n  country     pop18 access   area GDP_2015\n  <chr>       <dbl>  <dbl>  <dbl>    <dbl>\n1 Belgium  11413058   1951  30280  4.66e11\n2 Bulgaria  7050034   2007 108560  1.22e11\n3 Czechia  10610055   2004  77230  3.19e11\n4 Denmark   5781190   1973  42430  2.46e11\n5 Germany  82850000   1951 348540  3.60e12\n6 Estonia   1319133   2004  42390  3.51e10\nnames(EU)[1] \"country\"  \"pop18\"    \"access\"   \"area\"     \"GDP_2015\"\nstr(EU)tibble [28 × 5] (S3: tbl_df/tbl/data.frame)\n $ country : chr [1:28] \"Belgium\" \"Bulgaria\" \"Czechia\" \"Denmark\" ...\n $ pop18   : num [1:28] 11413058 7050034 10610055 5781190 82850000 ...\n $ access  : num [1:28] 1951 2007 2004 1973 1951 ...\n $ area    : num [1:28] 30280 108560 77230 42430 348540 ...\n $ GDP_2015: num [1:28] 4.66e+11 1.22e+11 3.19e+11 2.46e+11 3.60e+12 ..."},{"path":"data-manipulation-in-r.html","id":"variable-types-in-r","chapter":"Data Manipulation in R","heading":"Variable Types in R","text":"R distinguishes number different variable types broad overview . help deciding descriptive statistics calculate, variable type need recode (next step) achieve want. two general types:numeric – numberscharacter (also called string) – lettersWithin numeric can distinguish following:factor - nominalordered factor - ordinalinteger - numeric, “whole” numbers (discrete)numeric - number (interval ratio)Numerical variables already data set, attend nominal ordinal variables.","code":""},{"path":"data-manipulation-in-r.html","id":"nominal-variables","chapter":"Data Manipulation in R","heading":"Nominal Variables","text":"terms variable types encountered lecture week, country name nominal variable. need tell R turn factor variable. follows:","code":"\nEU$country = factor(EU$country)"},{"path":"data-manipulation-in-r.html","id":"ordinal-variables","chapter":"Data Manipulation in R","heading":"Ordinal Variables","text":"mentioned , variable access ordinal, therefore turned ordered factor. command follows almost identical producing factor variable, add option ordered = TRUE end:familiar European Studies, know accession wave got particular name. 1973 enlargement, example, called “First Enlargement”, 1981 wave Mediterranean Enlargement, forth. Let us create new variable uses names instead years.process little involved, requires new package installed loaded: dplyr. package part -called tidyverse suite packages designed make working R simpler commands shorter. can install calling install.packages(\"tidyverse\"). load tidyverse :command follows takes little explaining. start stating dataframe wish assign result , EU. name data frame contains data wish manipulate, also EU. symbol follows, \\%>\\%, reads “”, called “pipe”. take data frame EU “” carry function called mutate. creates new variable called wave recoding variable access_fac. command specifies categories “old” variable access_fac respective values “new” variable wave going . categories set quotation marks, factor / character categories.Please note colleagues department object use tidyverse “dialect” R, require use base R modules. However, module still using tidyverse, :textbook, going main textbook module 2026, uses tidyverse, think pedagogically wrong divert main text seminarsI think makes sense exclude one currently 22,505 packages4GGPLOT2 part tidyverse simplifies code generating figures significantly specific requirementsa lot support stackexchange geared toward tidyverse lot US-based data scientists work package, find easier solve problemsBut keep everybody happy, providing base R code whenever possible collapsible section like one:back recoding exercise . Please note original variable access_fac already ordered factor. Therefore, R (mutate function precise) also returns wave ordered factor. access_fac unordered factor (aka nominal variable), wave also unorderd factor. can specify option mutate function whether want factor ordered :access handful numbers, turned numerical value variable turned category new one. often recode variables continuous nature categories. Suppose, example, variable age contains age respondents survey. wanted recode categories 20-25, 26-35, etc., tedious assign category individual value age. cut() function comes handy, literally cuts variable chunks points specify. Let’s apply access variable., use mutate function, time naming new variable wave1 (overwrite wave variable created recode() function). cut() function splits numeric variable intervals using breaks specify function. Importantly, intervals left-open right-closed. means interval includes upper boundary, lower one. sounds complicated, let give example. , example, calledthen first interval start 10 include values greater 10 including 20. next interval contain values larger 20 including 30.apply access variable, therefore need specify breaks follows:first category (Founding) thus contains years including 1951, next category (First), years larger 1951 including 1973, forth. created categories (levels R terminology), can label accordingly labels.Recoding Factor VariableRecoding Ordered Factor Variables","code":"\nEU$access_fac = factor(EU$access, ordered = TRUE)\nlibrary(tidyverse)\nEU <- EU %>%\n  mutate(wave = recode(access_fac, '1951'=\"Founding\", \n                       '1973'= \"First\",\n                       '1981'= \"Mediterranean\",\n                       '1986' = \"Mediterranean\",\n                       '1995' = \"Cold War\",\n                       '2004' = \"Eastern\",\n                       '2007' = \"Eastern\",\n                       '2013' = \"Balkans\"))\nEU$wave <- NA\nEU$wave[EU$access_fac=='1951'] <- \"Founding\"\nEU$wave[EU$access_fac=='1973'] <- \"First\"\nEU$wave[EU$access_fac=='1981'] <- \"Mediterranean\"\nEU$wave[EU$access_fac=='1986'] <- \"Mediterranean\"\nEU$wave[EU$access_fac=='1995'] <- \"Cold War\"\nEU$wave[EU$access_fac=='2004'] <- \"Eastern\"\nEU$wave[EU$access_fac=='2007'] <- \"Eastern\"\nEU$wave[EU$access_fac=='2013'] <- \"Balkans\"\n\nEU$wave <- factor(EU$wave, ordered = TRUE)\nEU <- EU %>%\n  mutate(wave = recode(access_fac, '1951'=\"Founding\", \n                       '1973'= \"First\",\n                       '1981'= \"Mediterranean\",\n                       '1986' = \"Mediterranean\",\n                       '1995' = \"Cold War\",\n                       '2004' = \"Eastern\",\n                       '2007' = \"Eastern\",\n                       '2013' = \"Balkans\"), ordered=TRUE)\ncut(x, breaks = c(10, 20, 30))cut(access, breaks=c(1950, 1951, 1973, 1986, 1995, 2007, 2013), \nEU <- EU %>% \n  mutate(wave1=cut(access, \n                  breaks=c(1950, 1951, 1973, 1986, 1995, 2007, 2013), \n                  labels=c(\"Founding\",\"First\",\n                           \"Mediterranean\", \n                           \"Cold War\", \n                           \"Eastern\", \n                           \"Balkans\"))) \nlevels(EU$wave)[1] \"Founding\"      \"First\"         \"Mediterranean\" \"Cold War\"      \"Eastern\"       \"Balkans\"      \nEU$wave <- cut(EU$access, \n                  breaks=c(1950, 1951, 1973, 1986, 1995, 2007, 2013), \n                  labels=c(\"Founding\",\"First\",\n                           \"Mediterranean\", \n                           \"Cold War\", \n                           \"Eastern\", \n                           \"Balkans\"))"},{"path":"data-manipulation-in-r.html","id":"binary-dummy","chapter":"Data Manipulation in R","heading":"Binary Dummy","text":"often political science yes/scenarios, democracy yes , civil war, yes , etc. analyse scenarios, can create -called “dummy variables”. present example, let’s specify country whether founding member EU. factor variable exactly way initial recoding wave variable :much shorter way , however, shorter always preferred coding long leads result. can apply ifelse() function follows rationale: ifelse('condition', 'condition met, ', 'otherwise'). , access_fac==\"1951\" want assign value \"Yes\", \"\":Using ifelse, similar, pipe disappears:","code":"\nEU <- EU %>%\n  mutate(founding = recode(access_fac, '1951'=\"Yes\", \n                       '1973' = \"No\",\n                       '1981' = \"No\",\n                       '1986' = \"No\",\n                       '1995' = \"No\",\n                       '2004' = \"No\",\n                       '2007' = \"No\",\n                       '2013' = \"No\"))\nEU <- EU %>% \n   mutate(founding = factor(ifelse(access_fac==\"1951\", \"Yes\", \"No\"), \n                              levels =c(\"Yes\", \"No\")))\nEU$founding <- factor(ifelse(EU$access_fac==\"1951\", \"Yes\", \"No\"), \n                              levels =c(\"Yes\", \"No\"))"},{"path":"data-manipulation-in-r.html","id":"sub-setting-data","chapter":"Data Manipulation in R","heading":"Sub-Setting Data","text":"start analysing data, rarely need data time. might need variables, , example, want work certain observations, countries “founding” wave. cases, can subset data. show examples subsetting now.","code":""},{"path":"data-manipulation-in-r.html","id":"by-variable","chapter":"Data Manipulation in R","heading":"By Variable","text":"sure won’t need variable (remember, back button), can simply drop (.e. delete) . Let’s area variable:dropping multiple variables, can either perform operation time, use another command allows us operate multiple variables time. select() command comes tidyverse package specifies variables wish keep:creates new data frame called EU_pop containing variables country, pop18, access_fac, founding.package documentation offers basic instructions convert tidyverse (dyplyr, precise) code base R. solution previous code chunk:can, however, use command tell R variables drop adding minus sign variables want delete. following command produces exactly result one :","code":"\nEU$area <- NULL\nEU_pop <- select(EU, country, pop18, access_fac, founding)\nEU_pop <- subset(EU, country, pop18, access_fac, founding)\nEU_pop1 <- select(EU, -access, -GDP_2015)"},{"path":"data-manipulation-in-r.html","id":"by-observation","chapter":"Data Manipulation in R","heading":"By Observation","text":"Instead dropping keeping variables, can thing individual observations. , use slice() command (like cake) specify slices want drop keep. example drop Benelux countries delete observations 1, 16 19:Alternatively, interested Benelux countries subset observations:","code":"\nEU_nobenelux <- slice(EU, -1, -16, -19)\nEU_pop <- EU[c(-1, -16, -19),]\nEU_benelux <- slice(EU, 1, 16, 19)\nEU_pop <- EU[c(1, 16, 19),]"},{"path":"data-manipulation-in-r.html","id":"keep-if-a-variable-has-a-certain-value","chapter":"Data Manipulation in R","heading":"Keep if a variable has a certain value","text":"One useful commands filter(), allows us keep observations value variable particular number. example wanted conduct analysis countries population excess 10 million subset :list operators can use purpose:  Subsetting Data","code":"\nEU_pop_large <- filter(EU, pop18 > 10000000)\nEU_pop_large <- subset(EU, pop18 > 10000000)"},{"path":"data-manipulation-in-r.html","id":"ordering-data","chapter":"Data Manipulation in R","heading":"Ordering Data","text":"data set original state purposely ordered criterion, alphabetical order countries, etc. can use R exactly . Let us work subset containing three variables:lovely command ordering data called order(), called arrange()5. Let’s order countries ascending population new data frame called eu_order:can now display first 10 rows following command:content brackets refers rows (comma), columns (comma). want certain rows displaying variables, left space comma blank.can thing descending order calling:neat feature R allows us order observations one variable. example, order ascending accession wave first, ascending population 2018 follows:","code":"\nEU_subset <- select(EU, country, pop18, access)\neu_order <- arrange(EU_subset, pop18)\neu_order <- EU_subset[order(EU_subset$pop18),]\neu_order[1:10,]# A tibble: 10 × 3\n   country      pop18 access\n   <fct>        <dbl>  <dbl>\n 1 Malta       475701   2004\n 2 Luxembourg  602005   1951\n 3 Cyprus      864236   2004\n 4 Estonia    1319133   2004\n 5 Latvia     1934379   2004\n 6 Slovenia   2066880   2004\n 7 Lithuania  2808901   2004\n 8 Croatia    4105493   2013\n 9 Ireland    4838259   1973\n10 Slovakia   5443120   2004\neu_order <- arrange(EU_subset, desc(pop18))\neu_order[1:10,]# A tibble: 10 × 3\n   country           pop18 access\n   <fct>             <dbl>  <dbl>\n 1 Germany        82850000   1951\n 2 France         67221943   1951\n 3 United Kingdom 66238007   1973\n 4 Italy          60483973   1951\n 5 Spain          46659302   1986\n 6 Poland         37976687   2004\n 7 Romania        19523621   2007\n 8 Netherlands    17181084   1951\n 9 Belgium        11413058   1951\n10 Greece         10738868   1981\neu_order <- EU_subset[order(desc(EU_subset$pop18)),]\neu_order <- arrange(EU_subset, access, pop18)\n\neu_order[1:10,]# A tibble: 10 × 3\n   country           pop18 access\n   <fct>             <dbl>  <dbl>\n 1 Luxembourg       602005   1951\n 2 Belgium        11413058   1951\n 3 Netherlands    17181084   1951\n 4 Italy          60483973   1951\n 5 France         67221943   1951\n 6 Germany        82850000   1951\n 7 Ireland         4838259   1973\n 8 Denmark         5781190   1973\n 9 United Kingdom 66238007   1973\n10 Greece         10738868   1981\neu_order <- EU_subset[order(EU_subset$access,EU_subset$pop18),]\n\n# or slightly shorter \n\neu_order <- EU_subset[order(with(EU_subset, access,pop18)),]"},{"path":"data-manipulation-in-r.html","id":"grouping-data","chapter":"Data Manipulation in R","heading":"Grouping Data","text":"Looking last example, question might spring accession wave joining countries brought largest population increase average EU. can calculate summary statistics particular group , well, grouping . first step group data rows value:way: whenever grouped anything, finished analysing data grouped version essential ungroup data afterwards, don’t unintentionally keep using groups:let’s calculate average population size per accession wave elegant command combines multiple steps using pipes:now see new variable called avg contains average population increase wave. wave joining countries largest population average?","code":"\neu_access <- group_by(EU_subset, access)\nungroup(EU_subset)# A tibble: 28 × 3\n   country     pop18 access\n   <fct>       <dbl>  <dbl>\n 1 Belgium  11413058   1951\n 2 Bulgaria  7050034   2007\n 3 Czechia  10610055   2004\n 4 Denmark   5781190   1973\n 5 Germany  82850000   1951\n 6 Estonia   1319133   2004\n 7 Ireland   4838259   1973\n 8 Greece   10738868   1981\n 9 Spain    46659302   1986\n10 France   67221943   1951\n# ℹ 18 more rows\neu_popaccess <- EU_subset %>% \n  group_by(access) %>% \n  summarise(avg = mean(pop18))\n\neu_popaccess# A tibble: 8 × 2\n  access       avg\n   <dbl>     <dbl>\n1   1951 39958677.\n2   1973 25619152 \n3   1981 10738868 \n4   1986 28475164.\n5   1995  8151880.\n6   2004  7327746.\n7   2007 13286828.\n8   2013  4105493 \neu_popaccess1 <- aggregate(pop18 ~ access, \n                           data = EU_subset, \n                           FUN = mean )"},{"path":"data-manipulation-in-r.html","id":"combining-ordering-and-grouping-data","chapter":"Data Manipulation in R","heading":"Combining Ordering and Grouping Data","text":"question easy answer , accession waves. starts get unwieldy though, groups , can let R job combining first grouping, ordering. take grouped data frame eu_popaccess order descending avg:","code":"\neu_popaccess_order <- arrange(eu_popaccess, desc(avg))\n\neu_popaccess_order# A tibble: 8 × 2\n  access       avg\n   <dbl>     <dbl>\n1   1951 39958677.\n2   1986 28475164.\n3   1973 25619152 \n4   2007 13286828.\n5   1981 10738868 \n6   1995  8151880.\n7   2004  7327746.\n8   2013  4105493 \neu_popaccess_order <- eu_popaccess[order(desc(eu_popaccess$avg)),]"},{"path":"data-manipulation-in-r.html","id":"descriptive-statistics","chapter":"Data Manipulation in R","heading":"Descriptive Statistics","text":"covered quite large number descriptive statistics, far. :MeanMedianModeStandard DeviationVarianceQuartiles PercentilesRangeInterquartile RangeThey lot effort calculate hand, especially larger data sets, R can intuitive commands. First mean.median:can get information quartiles (remember median second quartile), mean, well minimum maximum one, simple command:Let’s now move measures variability. First range; can either calculate two commands finding minimum maximum separately, just ask R give values straight away:stadard deviation rather long-winded calculate hand, R command short sweet:know, variance squared standard deviation, can calculate command R, :Descriptive StatisticsNow relevant tools hand, complete following tasks:Generate descriptive statistics 3 variables.Recode variable ‘GDP_2015’ ordered factor called ‘gdp_level’ three levels called “low”, “medium”, “high” cut-points choosing.Produce tabulation ‘gdp_level’.","code":"\nmean(EU$pop18)[1] 18311106\nmedian(EU$pop18)[1] 9300319\nsummary(EU$pop18)    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n  475701  3781345  9300319 18311106 17766718 82850000 \nmin(EU$pop18)[1] 475701\nmax(EU$pop18)[1] 82850000\nrange(EU$pop18)[1]   475701 82850000\nsd(EU$pop18)[1] 23787945\nvar(EU$pop18)[1] 5.658663e+14"},{"path":"data-manipulation-in-r.html","id":"graphs","chapter":"Data Manipulation in R","heading":"Graphs","text":"R probably powerful statistics programme creating graphs. introductory level module, much time available seminars, able introduce commonly used ones; first instance histograms boxplots. introduce package ggplot2 simply best invention since sliced bread, gives pretty much endless optionality customising graphs show exactly want.Whenever produce graph use essay, dissertation, article, crucial graph able communicate message independently text. , reader able understand graph able appreciate fully message without read text. similar fashion, text always written way reader able understand without look graph. principle equally applies tables (PO12Q). follow principle assessments modules, marked .Chapter 4 “Visual Display Quantitative Information” Tufte (2001) reading list essential item, principles sets start book (p. 13) worthwhile repeating :Excellence statistical graphics consists complex ideas communicated clarity, precision, efficiency. Graphical displays shouldshow datainduce viewer think substance rather methodology, graphic design, technology graphic production, something elseavoid distorting data saypresent many numbers small spacemake large data sets coherentencourage eye compare different pieces datareveal data several levels detail, broad overview fine structureserve reasonably clear purpose: description, exploration, tabulation, decorationbe closely integrated statistical verbal descriptions data set.Graphics reveal data. Indeed graphics can precise revealing conventional statistical computations.","code":""},{"path":"data-manipulation-in-r.html","id":"basic-graphs","chapter":"Data Manipulation in R","heading":"Basic Graphs","text":"Let’s start histogram variable pop18. range pop18 variable 82 million - rather unwieldy imagine also put onto axes graphs, mostly consist zeros. let’s express population countries million instead:can now produce histogram. , sensible think number bars want histogram. smallest country just shy 500,000 inhabitants, whereas largest 82 million. , like x-axis run zero 100 (million) divide 5 bars. Accordingly, introducing 4 breaks x-axis following command:certainly histogram, conform principle graphs able communicate message independently, yet. Take label x-axis, example, EU$popmio mean? know, somebody doesn’t know R language wouldn’t. can tell R adjust axis label, well main title histogram follows:HistogramsThis fine now. Ugly, fine. show boxplot next, take process making look bit jazzy. command boxplot intuitive. default R arrange boxplot vertically. prefer horizontally, can set equally intuitive option.recognise descriptives calculated earlier summary() function:Explain outliers right mathematically.","code":"\nEU$popmio <- EU$pop18/1000000\nhist(EU$popmio, breaks=4)\nhist(EU$popmio, breaks=4,\n     xlab=\"Population in million\",\n     main=\"Histogram of EU Population (2018)\")\nboxplot(EU$popmio, horizontal = TRUE)\nsummary(EU$popmio)   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.4757  3.7813  9.3003 18.3111 17.7667 82.8500 "},{"path":"data-manipulation-in-r.html","id":"advanced-graphs","chapter":"Data Manipulation in R","heading":"Advanced Graphs","text":"graphs produced far functional, let’s honest, wouldn’t win beauty contests. , mentioned earlier, amazing package called ggplot2 changes dramatically. already installed part tidyverse. Otherwise, function :can just load :“gg” ggplot2 stands “grammar graphs”. familiar term “grammar”” learning language already. context, use grammar build sentences choosing arranging variety different components, subjects, verbs objects. know properly, can express exactly want say. grammar graphs adopts logic specifies number different components allow create graph able communicate exactly wish show.ggplot2 eight basic grammatical arguments: \nTable 2: GGPLOT Components\n like think using arguments like dressing morning. minimum common decency requires wear wish leave house underwear, trousers, top. Depending feel weather like, can add layers, like socks, jumper, scarf. exactly ggplot2. minimum produce plot need data frame, aesthetic mapping geom. produced minimalistic graph, can modify , adding components / arguments. can imagine possibilities almost endless, time deal minimum . problem, however, grammatical arguments (Stats, Position, Facets Scales) generally sensible defaults.work practice? Let us reproduce histogram age variable. start calling ggplot2 advise function data frame wish use (EU). second step, add geometry – case geom_histogram. Within geometry, need specify variable wish create distribution, language ggplot2 variable wish map geom Aesthetic. produce 5 bars , specify bandwidth 20 million (refers popmio).Annoyingly, ggplot places axis ticks middle bar WRONG histograms. need align boundaries bars. telling R boundary plot:shifted ticks left, now R decided label x-axis steps 25, whereas bars bandwidth 20. , variable name x-axis, instead label anybody understand. also prefer “Frequency” y-axis, instead “Count”. address concerns, simply add layer . First axis ticks. variable continuous, choose scale_x_continuous option, tell R break axis sequence starts zero, ends 100 steps 20 . labs argument adjust labelling intended:also removed background line principles set Tufte (2001, p. 96) adding theme_classic(). . graph can communicate message independently, looks aesthetically pleasing.present case population, displaying frequency y-axis sort sensible, usually dealing sample. count telling using percentages, instead. Let’s !","code":"\ninstall.packages(\"ggplot2\")\nlibrary(ggplot2)\nggplot(data=EU) +\n  geom_histogram(mapping=aes(popmio), binwidth = 20)\nggplot(data=EU) +\n  geom_histogram(mapping=aes(popmio), binwidth = 20, \n                 boundary = 0)\nggplot(data=EU) +\n  geom_histogram(mapping=aes(popmio), binwidth = 20, \n                 boundary = 0) +\n  scale_x_continuous(breaks = seq(0, 100, 20)) +\n  labs(x=\"Population (in million)\", y=\"Frequency\") +\n  theme_classic()\nhist(EU$popmio, breaks = 4,\n     xlab = \"Population (in million)\", ylab = \"Frequency\")"},{"path":"data-manipulation-in-r.html","id":"even-more-advanced-graphs","chapter":"Data Manipulation in R","heading":"Even More Advanced Graphs","text":"Unfortunately, easy, default way R, necessitates calculation within ggplot command. call ggplot use EU data set, select geom geom_histogram. specify binwidth 20 boundary zero, put popmio x-axis. Now comes point need something new, y equivalent frequency , percentage. achieve advise R put density (relative frequency lecture week 5), multiply density 100 get percentage. Nothing changed scaling x-axis previous plot, can copy paste scale_x_continuous section, well labelling x-axis. last step, now also need adjust label y-axis, now percentage , frequency. result :Jazzy Graphs GGPLOT","code":"\nggplot(data = EU) + \n  geom_histogram(binwidth = 20, boundary = 0,\n                 aes(x= popmio, \n                     y = (..count..)/sum(..count..)*100)) +\n  scale_x_continuous(breaks = seq(0, 100, 20)) +\n  labs(x=\"Population (in million)\", y=\"percent\")  +\n  theme_classic()\n# Create histogram data without plotting\nh <- hist(EU$popmio, \n         breaks = seq(0, 100, by = 20), \n         plot = FALSE)\n\n# Normalize counts to percentages\nh$counts <- h$counts / sum(h$counts) * 100\n\n# Plot histogram\nplot(h, \n    freq = FALSE, \n    xlab = \"Population (in million)\", \n    ylab = \"percent\", \n    main = \"\")"},{"path":"data-manipulation-in-r.html","id":"organising-code-in-the-rscript","chapter":"Data Manipulation in R","heading":"Organising Code in the RScript","text":"Now probably good time make aware organising code runs several lines. also written code last graph asbut made rather difficult disentangle spot structure graph straight away. also good idea structure code logical way allows reader understand easily possible. R smart way indents next line pressing “enter” RScript automatically appropriate position. see example inthe aes belongs geom_histogram layer indented just starts flush first argument (binwidth) within layer.","code":"\nggplot(data = EU) + \n  geom_histogram(binwidth = 20, boundary = 0, aes(x= popmio, y = (..count..)/sum(..count..)*100)) + scale_x_continuous(breaks = seq(0, 100, 20)) + labs(x=\"Population\", y=\"percent\") + theme_classic()\nggplot(data = EU) + \n  geom_histogram(binwidth = 20, boundary = 0,\n                 aes(x= popmio, \n                     y = (..count..)/sum(..count..)*100)) +\n  scale_x_continuous(breaks = seq(0, 100, 20)) +\n  labs(x=\"Population (in million)\", y=\"percent\") +\n  theme_classic()"},{"path":"data-manipulation-in-r.html","id":"exercises-1","chapter":"Data Manipulation in R","heading":"Exercises","text":"Using commands, moving beyond help today’s reading, complete following tasks:Produce two base-R graphs different types (e.g. histogram, bar chart, box--whisker plot) separate variables EU data set.Produce two ggplot graphs different types (e.g. histogram, bar chart, box--whisker plot) separate variables EU data set. Google find geoms.","code":""},{"path":"data-manipulation-in-r.html","id":"captions-for-tables-and-figures-in-word","chapter":"Data Manipulation in R","heading":"Captions for Tables and Figures in Word","text":"essays, dissertation articles, refer tables figures text. Now, can writing “figure ”. elegant. Also, happens change layout sudden “figure ” becomes “figure ”. causes additional work edit text check references tables figures done (tedious beyond description), also risk miss one process.MS Word nifty function allows insert captions figures tables, insert cross-references text get updated automatically send document printer. :Say, figure inserted Word. now click , hover bottom right-hand square, right-click mouse. resulting context menu select “Insert Caption”.results following window:Select whether item want describe figure, table. make sure place caption “” item (default). type caption box top, “Figure 1: Skewness Distributions”. Make sure caption telling. reader needs know caption figure table . click OK, document looks like :Now start writing text come point refer figure question. , select “Insert” “Cross-Reference”” select following options pop-window:text look like :don’t worry now sequence numbering . insert another figure one, insert cross-reference text , sequence automatically updated former “Figure 1” becomes “Figure 2”. Tables figures separate sequences numbering.One last word display data tables: screenshot tables R insert presentations. look ugly unprofessional. Make effort create proper table, either Word Excel populate manually data R. insertion captions cross-references described .","code":""},{"path":"exercises-2.html","id":"exercises-2","chapter":"Exercises","heading":"Exercises","text":"","code":""},{"path":"exercises-2.html","id":"exploring-the-ess-core-exercises","chapter":"Exercises","heading":"Exploring the ESS – Core Exercises","text":"Open ESS9 dataset R attach .Identify variable “Left-right placement”.\nCheck formatting questionnaire: 77, 88 99 mean?\nlevel variable?\nSummarise functions class, str, head\nfunctions return?\nCheck formatting questionnaire: 77, 88 99 mean?level variable?Summarise functions class, str, headWhat functions return?Apply steps variable “European unification:”go already gone far”.\ndisplay first 20 values two variables \nCheck structure ‘table’ function tabulate two variables\nCan see major difference regarding non positive answers (ie outside proposed scale)?\ndisplay first 20 values two variables aboveCheck structure ‘table’ function tabulate two variablesCan see major difference regarding non positive answers (ie outside proposed scale)?Consider function rm(list=ls())\nfunction rm stand ?\nuseful can function future exercises?\nfunction rm stand ?useful can function future exercises?Univariate Statistics Recoding\nCalculate two means, using valid values (check mean function beforehand)\nLeft-right, regroup values, using three different methods:\nrecode\nconvert factor format using .factor\nassign value labels using levels\n0-1 “far left”\n2-3 “left”,\n4-6 “centre”,\n7-8 “right”\n9-10 “far right”\n\n\nCalculate two means, using valid values (check mean function beforehand)Left-right, regroup values, using three different methods:\nrecode\nconvert factor format using .factor\nassign value labels using levels\n0-1 “far left”\n2-3 “left”,\n4-6 “centre”,\n7-8 “right”\n9-10 “far right”\n\nrecodeconvert factor format using .factorassign value labels using levels\n0-1 “far left”\n2-3 “left”,\n4-6 “centre”,\n7-8 “right”\n9-10 “far right”\n0-1 “far left”2-3 “left”,4-6 “centre”,7-8 “right”9-10 “far right”","code":""},{"path":"exercises-2.html","id":"exploring-the-ess-going-further","chapter":"Exercises","heading":"Exploring the ESS – Going Further","text":"Using new, transformed variables:\nCalculate means UK . may use [variable == \"value\"] subscript\nmean compare average Europe? France?\nPresent frequencies means three samples one unique table\nInstall load questionr package. Use function ‘freq’ calculate , percentages.\nCompare deviations mean UK Germany using function abs (absolute value, means value negative signs deleted)\nCompare mean, median, mode, variance standard deviation UK Germany\nCalculate means UK . may use [variable == \"value\"] subscriptHow mean compare average Europe? France?Present frequencies means three samples one unique tableInstall load questionr package. Use function ‘freq’ calculate , percentages.Compare deviations mean UK Germany using function abs (absolute value, means value negative signs deleted)Compare mean, median, mode, variance standard deviation UK GermanyTry 3 kinds graphs two variables separately, using appropriate original transformed values. Assess compare relevance graphTabulate two variables original format using table(X,Y). Interpret output.Repeat transformed format: Interpret output.Try using questionr::cpropGraph two variables using ‘plot’ (make sure choose right versions variables). can conclude graph?","code":""},{"path":"homework-for-week-3.html","id":"homework-for-week-3","chapter":"Homework for Week 3","heading":"Homework for Week 3","text":"Finish working worksheet.Add note underneath code chunk RScript (starting line #), translating code plain English.Read required literature week 3.Work week’s flashcards familiarise relevant R functions.Find example NEW function apply R ensure works.","code":""},{"path":"glossary-1.html","id":"glossary-1","chapter":"Glossary","heading":"Glossary","text":" \nTable 3: Glossary Week 2\n ","code":""},{"path":"flashcards-1.html","id":"flashcards-1","chapter":"Flashcards","heading":"Flashcards","text":"\n\n \n\n\n \n\n\n \n","code":""},{"path":"foundations-of-statistical-inference.html","id":"foundations-of-statistical-inference","chapter":"Foundations of Statistical Inference","heading":"Foundations of Statistical Inference","text":"","code":""},{"path":"foundations-of-statistical-inference.html","id":"self-assessment-questions","chapter":"Foundations of Statistical Inference","heading":"Self-Assessment Questions6","text":"sample distribution?sample distribution differ sampling distribution?need sampling distribution?central limit theorem postulate, need ?difference normal distribution t-distribution?Please stop don’t go beyond point compared notes answers.","code":""},{"path":"foundations-of-statistical-inference.html","id":"how-to-read-a-z-table","chapter":"Foundations of Statistical Inference","heading":"How to read a z-table","text":"lecture learned Normal Distribution. Normal Distribution, area curve determined number standard deviations around mean \\(\\mu\\). number expressed form z-score defined :\\[\\begin{equation}\nz=\\frac{\\text{Observation} - \\text{Mean}}{\\text{Standard Deviation}}=\\frac{y-\\mu}{\\sigma}\n\\end{equation}\\]put words, z takes difference particular value interested mean. divides distance standard deviation, order express distance units standard deviations. ? know Normal Distribution area interval mean \\(\\pm\\) one standard deviation equal 68%. equivalent blue area Figure 5. also means remaining white area equal 32%, white section side 16%.\nFigure 5: Area Normal Distribution\nImagine now, took point minus one standard deviation starting point, turn right, Figure 6. white area still 16%, blue area needs 84%.\nFigure 6: Right-Tail Probability\nprobability finding value larger equivalent minus one standard deviation 84%. call right-tail probability. beauty can point x-axis. know many standard deviations value removed mean, can use right-tail probability assess likely value higher (lower) value occur.number standard deviations z-score. Every z-score right-tail probability associated . probabilities listed Normal Table. read Table? Let take example used lecture . crime rate 32 Scottish councils normally distributed, \\(\\mu=280.36\\) \\(\\sigma=69.26\\). can see distribution visualised Figure 7.\nFigure 7: Distribution Crime Rate 32 Scotting Councils, 2020\nquestion likely us find council crime rate larger 400.\nwanted visualise , need area right 400 x-axis. look like :\nFigure 8: Probability Council Crime Rate \\(\\geq\\) 400\norder calculate size area, first took difference 400 280.36 119.64. divided 119.64 standard deviation 69.26, express distance units standard deviation. result 1.727404. know, therefore, crime rate 400 x-axis located 1.727404 standard deviations right mean.now need find right-tail probability belongs value. left-column Normal Table find z-values first decimal place. Move 1.7. turn right, hit second decimal place. value 1.73 go four columns right (first one decimal 0). z-score 1.73 area 0.0418, 4.2%. can therefore say average crime rate 280.36 standard deviation 69.26, probability finding council crime rate higher 400 4.2%.moving , need note z can negative. assessing probability finding council crime rate less 160.5 (280.36 - 1.73*69.26) get z-score -1.73. Normal Distribution symmetrical, can use process, need reverse logic. right tail probability gives us area right z-score, negative z-score give us area left z-score. , probability finding council crime rate less 160.5 also 4.2%.knowledge hand, let’s calculations.","code":""},{"path":"exercises-3.html","id":"exercises-3","chapter":"Exercises7","heading":"Exercises7","text":"","code":""},{"path":"exercises-3.html","id":"conceptual-exercises","chapter":"Exercises7","heading":"Conceptual Exercises","text":"mean weight bag apples 1 kg. weight bags normally distributed around mean standard deviation 50g.\nBilly looking heaviest bag possible finds one 1082 g. probability finding heavier bag?\nprobability Billy find bag lighter 870g?\nresults . b. change standard deviation 40g? ?\nBilly looking heaviest bag possible finds one 1082 g. probability finding heavier bag?probability Billy find bag lighter 870g?results . b. change standard deviation 40g? ?z-value gives right-tail probability 2.5%?z-value 1.13 right-tail probability %?average mark fictitious module 62.3 standard deviation 8.5. probability fail module (pass-mark=50)?","code":""},{"path":"exercises-3.html","id":"r-exercises---core","chapter":"Exercises7","heading":"R Exercises - Core","text":"Open European Social Survey data, time use Wave 7 (2014) need download ESS website. Name conveniently attach .Univariate Statistics\nIdentify height weight variables\nUse appropriate function summarise lines\nPlot two variables separately boxplots\nPlot two variables separately histograms using function ‘hist’\nAdjust bars 5 cm 5 kg (close numbers can)\nDiscuss advantage various break values\nweight’s height’s modes?\nPlot using ‘density’ variable (density function smoothes distribution)\nCalculate relevant central values variables. match intuition?\nIdentify height weight variablesUse appropriate function summarise linesPlot two variables separately boxplotsPlot two variables separately histograms using function ‘hist’Adjust bars 5 cm 5 kg (close numbers can)Discuss advantage various break valuesWhat weight’s height’s modes?Plot using ‘density’ variable (density function smoothes distribution)Calculate relevant central values variables. match intuition?Sampling\nExecute following three times, explain function ‘sample’ :\n\nsample(1:20,5)\nExecute following three times, explain function ‘set.seed’ :\n\nset.seed(1)\nsample(1:20,5)\nSelect random sample 100 ESS data frame, using “set.seed(1)”.\nExecute following three times, explain function ‘sample’ :Execute following three times, explain function ‘set.seed’ :Select random sample 100 ESS data frame, using “set.seed(1)”.Sampling Distributions\nGenerate vector “w” containing 10000 normally distributed numbers mean 0 standard deviation 1. Convert vector data frame “dfw”.\nUsing ggplot, plot histogram variable w (hint: use “after_stat(density)”), overlay histogram red density curve. Label graph appropriately.\nCreate empty vector, called “n30”. Write function draws 9000 samples size 30 variable w stores mean sample vector “n30”. Convert vector “n30” data frame.\nUsing ggplot, plot histogram variable n30 (hint: use “after_stat(density)”), overlay histogram red density curve. Label graph appropriately.\nPlot two graphs just created grid two columns 1 row. (Hint: use package ‘gridExtra’)\nInterpret juxtaposition graphs.\nGenerate vector “w” containing 10000 normally distributed numbers mean 0 standard deviation 1. Convert vector data frame “dfw”.Using ggplot, plot histogram variable w (hint: use “after_stat(density)”), overlay histogram red density curve. Label graph appropriately.Create empty vector, called “n30”. Write function draws 9000 samples size 30 variable w stores mean sample vector “n30”. Convert vector “n30” data frame.Using ggplot, plot histogram variable n30 (hint: use “after_stat(density)”), overlay histogram red density curve. Label graph appropriately.Plot two graphs just created grid two columns 1 row. (Hint: use package ‘gridExtra’)Interpret juxtaposition graphs.","code":"\nsample(1:20,5)\nset.seed(1)\nsample(1:20,5)"},{"path":"exercises-3.html","id":"r-exercises---going-further","chapter":"Exercises7","heading":"R Exercises - Going Further","text":"Complete Section 4 Core Exercises.\nRepeat steps -d following distributions:\nuniform distribution min = 0, max = 1.\nbeta distribution, Beta(2,5).\n\nbeta distribution represent?\nCreate graph distribution type new row, population sampling distributions placed next .\nComplete Section 4 Core Exercises.Repeat steps -d following distributions:\nuniform distribution min = 0, max = 1.\nbeta distribution, Beta(2,5).\nuniform distribution min = 0, max = 1.beta distribution, Beta(2,5).beta distribution represent?Create graph distribution type new row, population sampling distributions placed next .","code":""},{"path":"exercises-3.html","id":"solutions","chapter":"Exercises7","heading":"Solutions","text":"can find Solutions Downloads Section.","code":""},{"path":"homework-for-week-4.html","id":"homework-for-week-4","chapter":"Homework for Week 4","heading":"Homework for Week 4","text":"Finish working worksheet.Add note underneath code chunk RScript (starting line #), translating code plain English.Read required literature week 4.Work week’s flashcards familiarise relevant R functions.Find example NEW function apply R ensure works.","code":""},{"path":"glossary-2.html","id":"glossary-2","chapter":"Glossary","heading":"Glossary","text":" \nTable 4: Glossary Week 3\n ","code":""},{"path":"flashcards-2.html","id":"flashcards-2","chapter":"Flashcards","heading":"Flashcards","text":"\n\n \n\n\n \n\n\n \n","code":""},{"path":"confidence-intervals.html","id":"confidence-intervals","chapter":"Confidence Intervals","heading":"Confidence Intervals","text":"","code":""},{"path":"confidence-intervals.html","id":"self-assessment-questions-1","chapter":"Confidence Intervals","heading":"Self-Assessment Questions8","text":"words:significance test ?Give example significance test.Give example hypothesis testable.Explain difference significance test confidence interval.Explain relationship size p-value Type II Errors.Please stop don’t go beyond point compared notes answers.","code":""},{"path":"confidence-intervals.html","id":"calculating-confidence-intervals","chapter":"Confidence Intervals","heading":"Calculating Confidence Intervals","text":"Just reminder, confidence interval?Confidence IntervalA confidence interval estimated range, based sample, likely contain true population parameter (mean). sampling process repeated many times, approximately \\((1 - \\alpha) \\times 100\\%\\) resulting intervals contain true parameter. value \\(\\alpha\\) determines confidence level – example, \\(\\alpha = 0.05\\) corresponds 95% confidence level, \\(\\alpha = 0.01\\) corresponds 99%. (Reiche, forthcoming)two scenarios calculating confidence intervals: (1) know \\(\\sigma\\) (standard deviation population distribution), (2) don’t know \\(\\sigma\\). Let take two scenarios turn:","code":""},{"path":"confidence-intervals.html","id":"we-know-sigma","chapter":"Confidence Intervals","heading":"1. We know \\(\\sigma\\)","text":"population distribution known population standard deviation (\\(\\sigma\\)) available, can construct confidence interval using standard normal distribution (z-distribution).Assume sample student ages sample size \\(n = 81\\) sample mean \\(\\bar{y} = 26\\). population standard deviation known \\(\\sigma = 9\\). aim construct 99% confidence interval true population mean age students. (lecture, considered 95% confidence level scenario.)begin calculating standard error sample mean:\\[\\begin{equation*}\n    \\sigma_{\\bar{y}} = \\frac{\\sigma}{\\sqrt{n}}\n\\end{equation*}\\]\\[\\begin{equation*}\n    \\sigma_{\\bar{y}} = \\frac{9}{\\sqrt{81}} = 1\n\\end{equation*}\\]important bear mind construction confidence intervals, just need right-tail probability, area trying cover distribution symmetrical around mean. visualised Figure 9 area defined \\(\\pm\\) 1.96 standard deviations around mean.\nFigure 9: 95 Percent Confidence Interval around Mean\norange area needs 95%, remaing areas left right need equal 5% jointly. 2.5%. look Table right-tail probabilities, therefore need look z-score corresponds 0.025 (2.5%). look Normal Table (see Statistical Tables), find z=1.96.Now, question arises, many standard deviations need 99% confidence interval. area left right needs jointly 1%, 0.05% side. consult Normal Table , try find z-score 0.005. exact value available, either 0.0051, 0.0049. 0.0051 lead confidence interval 98.98%, quite large enough. therefore need go 0.0049, corresponding z-score z=2.58.\\[\\begin{equation*}\ny = \\bar{y} \\pm 2.58 \\times \\sigma_{\\bar{Y}}\n\\end{equation*}\\]Popping values receive\\[\\begin{equation*}\n26 \\pm 2.58 \\times 1\n\\end{equation*}\\]result, can say 99% confident true average age students Warwick lies 23.42 28.58. Note confidence interval wider 95% one boundaries defined 24.04 27.96. went higher certainty , confidence interval became wider. want interval contain true average 99 100 samples, need cast net wider content 95.","code":""},{"path":"confidence-intervals.html","id":"we-dont-know-sigma","chapter":"Confidence Intervals","heading":"2. We don’t know \\(\\sigma\\)","text":"don’t know population distribution standard deviation, need use t-distribution. know lecture, t-distribution shape shifter. width depends degrees freedom: degrees freedom , narrow, closer normal distribution comes. df=30 shapes t-distribution normal distribution almost identical. can see following Figure, comparing yellow t-distribution \\(df=30\\) black (normal) distribution.\nFigure 10: Comparison t-Distributions\nreversed logic, also means t-distribution rather wide small sample sizes (small df). Consequently, confidence interval given level (e.g. 99%) much wider small sample size normal distribution (t-distributions higher sample sizes). Let illustrate using sample average normal distribution example , \\(\\bar{y}=26\\). sample standard deviation (\\(s\\)) 2. sample size small, \\(n=4\\). , want interval within find 99% confidence true average age students.start estimating standard error:\\[\\begin{equation*}\n    se=\\frac{s}{\\sqrt{n}}\n\\end{equation*}\\]\\[\\begin{equation*}\nse=\\frac{2}{\\sqrt{4}}=1\n\\end{equation*}\\]time search t-Table, taking account degrees freedom. \\(n=4\\), means \\(df=3\\). Conveniently, Table lists top desired confidence interval. \\(df=3\\) 99% confidence interval, corresponding t-value 5.841. , calculate:\\[\\begin{equation*}\n\\bar{y} \\pm 5.841 \\times se\n\\end{equation*}\\]\\[\\begin{equation*}\n26 \\pm 5.841 \\times 1\n\\end{equation*}\\]resulting boundaries 20.159 lower boundary, 31.841 upper boundary. far wider 99% confidence interval obtained normal distribution, lower upper boundaries 23.42 28.58, respectively. reflection fact small sample (\\(n=4\\)) base inference therefore lot uncertainty inference.conclude, fair say procedure essentially normal procedure, go extra step taking account degrees freedom.now ready exercises.","code":""},{"path":"exercises-4.html","id":"exercises-4","chapter":"Exercises","heading":"Exercises","text":"","code":""},{"path":"exercises-4.html","id":"conceptual-exercises-1","chapter":"Exercises","heading":"Conceptual Exercises9","text":"researcher analysing individuals’ relative fear victim burglary 1-100 scale. random sample 9 individuals found mean score 47 scale sample variance 158.76 fear burgled.\ndistribution used calculate 80% confidence interval around mean?\nConstruct interval.\ndistribution used calculate 80% confidence interval around mean?Construct interval.investigating height men UK. obtained random sample 100 UK men found mean height 180cm standard deviation 10cm.\nConstruct 95% confidence interval mean height UK males.\nSelect true statements concerning constructed confidence interval justify choice statement.\nprobability population mean within upper lower bounds 95%.\n95% men’s heights fall upper lower bound.\n95% cases sample fall upper lower bound.\naverage 95% confidence intervals constructed contain population mean.\naverage 95% means samples 100 respondents fall within upper lower bands.\n\nConstruct 95% confidence interval mean height UK males.Select true statements concerning constructed confidence interval justify choice statement.\nprobability population mean within upper lower bounds 95%.\n95% men’s heights fall upper lower bound.\n95% cases sample fall upper lower bound.\naverage 95% confidence intervals constructed contain population mean.\naverage 95% means samples 100 respondents fall within upper lower bands.\nprobability population mean within upper lower bounds 95%.95% men’s heights fall upper lower bound.95% cases sample fall upper lower bound.average 95% confidence intervals constructed contain population mean.average 95% means samples 100 respondents fall within upper lower bands.","code":""},{"path":"exercises-4.html","id":"r-exercises---core-1","chapter":"Exercises","heading":"R Exercises - Core","text":"exercises use ks2 dataset. data comprises fictitious10 average grades Key Stage 2 (KS2) students UK, 1,980 KS2 students’ test scores included reading (reading), mathematics (maths), grammar, punctuation, spelling (gps), well mean three test scores (avg_all). test scores standardised, 80 representing lowest possible mark, 120 representing highest possible mark, 100 representing minimum passing mark, -1 representing ungraded test.Interpreting Significance TestsIn exercises, reporting statistical results generally, ’ll required interpret outcome significance test. well, ’s important use language reflects null hypothesis significance testing (NHST) actually tells us, without overstating test can conclude.NHST works starting null hypothesis - usually claim like “effect” “difference”. use data test whether assumption plausible. p-value small, means results extreme one observed — extreme — rare null hypothesis true. , take evidence null. p-value large, data consistent null. ’s interpretation stop (least introductory level, avoid stretching overstating).two possible outcomes significance test: (1) p-value required significance level, (2) p-value required significance level. Let’s look turn:p-value required significance level, can say things like:\n“evidence effect.”\n“reject null hypothesis.”\n“data provide evidence null hypothesis.”\n“statistically significant evidence difference (relationship, effect).”\n\nAvoid phrasing implies certainty, :\n🚫 “proved alternative hypothesis.”\n🚫 “proved effect.”\n🚫 “accept alternative hypothesis.”\np-value required significance level, can say things like:“evidence effect.”“reject null hypothesis.”“data provide evidence null hypothesis.”“statistically significant evidence difference (relationship, effect).”Avoid phrasing implies certainty, :🚫 “proved alternative hypothesis.”🚫 “proved effect.”🚫 “accept alternative hypothesis.”p-value required significance level reject null hypothesis, can say things like:\n“insufficient evidence effect (difference, relationship).”\n“reject null hypothesis.”\n“fail reject null hypothesis.”\n“results consistent null hypothesis.”\n\nAvoid phrasing overstates test can tell , :\n🚫 “proved null hypothesis.”\n🚫 “reject alternative hypothesis.”\n🚫 “null hypothesis true.”\np-value required significance level reject null hypothesis, can say things like:“insufficient evidence effect (difference, relationship).”“reject null hypothesis.”“fail reject null hypothesis.”“results consistent null hypothesis.”Avoid phrasing overstates test can tell , :🚫 “proved null hypothesis.”🚫 “reject alternative hypothesis.”🚫 “null hypothesis true.”taught quantitative political analysis many years, know students love use word “prove” interpret results. proof significance testing, deal probability statements, certainty.Load ks2 dataset R. Remove observations ungraded test scores.Calculate means standard deviations three subjects. Write brief description insights can drawn values.Conduct t-test see means three subjects’ marks statistically different 100 95% confidence level. Identify three ways suggest statistically significant insignificant differences.Conduct t-test see mean average score three tests statistically less 105 99% confidence level. Interpret results.following questions look students’ English abilities generally.\nCreate new variable called english, consists average reading grammar, punctuation, spelling variables.\nConduct t-test see mean average score new English variable statistically less 105 99.9% confidence level. Interpret results.\nConduct t-test see mean average score new English variable statistically different 105 99.9% confidence level. Interpret results.\ndifference interpretation two tests? differences results? ?\nCreate new variable called english, consists average reading grammar, punctuation, spelling variables.Conduct t-test see mean average score new English variable statistically less 105 99.9% confidence level. Interpret results.Conduct t-test see mean average score new English variable statistically different 105 99.9% confidence level. Interpret results.difference interpretation two tests? differences results? ?tasked investing performance students passed mathematics . following tests, use 95% confidence level.\nCreate binary variable two categories: passed mathematics (100 \\(\\leq\\) mark) failed mathematics (mark \\(<\\) 100).\nConduct proportion test see proportion students fail mathematics 10% greater. Interpret results.\nConduct t-test group fail mathematics see , average, marks English statistically less 100. Interpret results.\nConduct t-test group pass mathematics see , average, marks grammar, spelling, punctuation statistically greater 105. Interpret results.\nCreate binary variable two categories: passed mathematics (100 \\(\\leq\\) mark) failed mathematics (mark \\(<\\) 100).Conduct proportion test see proportion students fail mathematics 10% greater. Interpret results.Conduct t-test group fail mathematics see , average, marks English statistically less 100. Interpret results.Conduct t-test group pass mathematics see , average, marks grammar, spelling, punctuation statistically greater 105. Interpret results.Now worth investigating students fail least one subject perform.\nCreate binary variable two categories: passed three subjects (marks greater equal 100) failed least one subject (one marks less 100).\ncan hypothesised group students failed mean test marks significantly pass mark 100. Test interpret findings respect statistical practical significance test.\nCreate binary variable two categories: passed three subjects (marks greater equal 100) failed least one subject (one marks less 100).can hypothesised group students failed mean test marks significantly pass mark 100. Test interpret findings respect statistical practical significance test.","code":""},{"path":"exercises-4.html","id":"r-exercises---going-further-1","chapter":"Exercises","heading":"R Exercises - Going Further","text":"Imagine part team work working within Department Education, tasked investigating sample produce recommendations policymakers.\nNormalise variable contains average three marks setting lowest mark (80) 0, highest mark (120) 100, minimum pass mark (100) 50. Justify might useful normalise marks scale non-specialist policymakers.\nConstruct categorical variable consists five categories: 0-49.99 (Fail), 50-59.99 (Pass), 60-60.99 (Merit), 70-79.99 (Distinction), 80+ (Distinction+).\nAnswer following questions write answers intended non-specialist policy making knowledge statistics:\naverages Pass, Merit, Distinction groups different middle marks (55, 65, 75, respectively)? , direction?\naverage mark Distinction+ group lower maximum mark group?\nmean mark Fail group higher median mark group? skew indicate distribution?\n\nNormalise variable contains average three marks setting lowest mark (80) 0, highest mark (120) 100, minimum pass mark (100) 50. Justify might useful normalise marks scale non-specialist policymakers.Construct categorical variable consists five categories: 0-49.99 (Fail), 50-59.99 (Pass), 60-60.99 (Merit), 70-79.99 (Distinction), 80+ (Distinction+).Answer following questions write answers intended non-specialist policy making knowledge statistics:\naverages Pass, Merit, Distinction groups different middle marks (55, 65, 75, respectively)? , direction?\naverage mark Distinction+ group lower maximum mark group?\nmean mark Fail group higher median mark group? skew indicate distribution?\naverages Pass, Merit, Distinction groups different middle marks (55, 65, 75, respectively)? , direction?average mark Distinction+ group lower maximum mark group?mean mark Fail group higher median mark group? skew indicate distribution?","code":""},{"path":"exercises-4.html","id":"solutions-1","chapter":"Exercises","heading":"Solutions","text":"can find Solutions Downloads Section.","code":""},{"path":"homework-for-week-5.html","id":"homework-for-week-5","chapter":"Homework for Week 5","heading":"Homework for Week 5","text":"Finish working worksheet.Add note underneath code chunk RScript (starting line #), translating code plain English.Read required literature week 5.Work week’s flashcards familiarise relevant R functions.Find example NEW function apply R ensure works.","code":""},{"path":"glossary-3.html","id":"glossary-3","chapter":"Glossary","heading":"Glossary","text":" \nTable 5: Glossary Week 4\n ","code":""},{"path":"flashcards-3.html","id":"flashcards-3","chapter":"Flashcards","heading":"Flashcards","text":"\n\n \n\n\n \n\n\n \n","code":""},{"path":"causality-and-consolidation.html","id":"causality-and-consolidation","chapter":"Causality and Consolidation","heading":"Causality and Consolidation","text":"","code":""},{"path":"causality-and-consolidation.html","id":"self-assessment-questions-2","chapter":"Causality and Consolidation","heading":"Self-Assessment Questions11","text":"causality important topic?Explain role symmetry asymmetry causality.Choosing one literature strands presented literature, explain approach causality.issue causality affect language use research?Please stop don’t go beyond point compared notes answers.","code":""},{"path":"causality-and-consolidation.html","id":"case-study","chapter":"Causality and Consolidation","heading":"Case Study","text":"working “Scottish Index Multiple Deprivation”. data taken https://www.gov.scot/collections/Scottish Index Multiple Deprivation relative measure deprivation across 6,976 small areas (called data zones). area identified ‘deprived’, can relate people low income can also mean fewer resources opportunities. SIMD looks extent area deprived across seven domains: income, employment, education, health, access services, crime housing.\nSIMD Scottish Government’s standard approach identify areas multiple deprivation Scotland. can help improve understanding outcomes circumstances people living deprived areas Scotland. can also allow effective targeting policies funding aim wholly partly tackle take account area concentrations multiple deprivation.data set provided combines two waves SIMD, namely2016: containing data collected 2011 20142020: containing data collected 2014 2018Rather presenting data pertaining individual data zones (n=6,976), chosen aggregate data zones corresponding councils, reducing number observations 32.","code":""},{"path":"causality-and-consolidation.html","id":"codebook","chapter":"Causality and Consolidation","heading":"Codebook","text":" \nTable 6: SIMD Codebook\n ","code":""},{"path":"causality-and-consolidation.html","id":"data-exploration","chapter":"Causality and Consolidation","heading":"Data Exploration","text":"starting, need load libraries install packages already installed. exercises using tidyverse package.Set working directory, place data set , load R.Create new RScript case study annotate go exercises presented .Load tidyverse package.","code":""},{"path":"causality-and-consolidation.html","id":"descriptive-statistics-1","chapter":"Causality and Consolidation","heading":"Descriptive Statistics","text":"Produce descriptive statistics three numerical variables.","code":""},{"path":"causality-and-consolidation.html","id":"visualisation","chapter":"Causality and Consolidation","heading":"Visualisation","text":"Let’s visualise distribution variable alc16.\nFigure 11: Distribution Alcohol-Related Hospital Admissions (2011-2014)\nReproduce Figure 11.distribution tell us alcohol-related admissions hospital?shape distribution Figure 11 relate descriptive statistics calculated previous Section?happen shape distribution median smaller mean?","code":""},{"path":"causality-and-consolidation.html","id":"hypothesis","chapter":"Causality and Consolidation","heading":"Hypothesis","text":"interested alcohol-related admissions hospital affected mortality rates Scotland. following scatter plot uses variables alc16 mortality20.\nFigure 12: Alcohol-Related Hospital Admissions Mortality\nReproduce Figure 12.Based scatter plot, formulate alternative null hypotheses:   H\\(\\pmb{_0}\\):\n   H\\(\\pmb{_\\text{}}\\):","code":""},{"path":"causality-and-consolidation.html","id":"sampling","chapter":"Causality and Consolidation","heading":"Sampling","text":"data frame using far represents population. Let us now draw random sample 15 councils follows:Explain purpose set.seed function.","code":"\nset.seed(6)\nsample <- sample_n(simd, 15)"},{"path":"causality-and-consolidation.html","id":"inferential-statistics","chapter":"Causality and Consolidation","heading":"Inferential Statistics","text":"Let us now see mortality ratio changed two waves 2016 2020. worked example lecture, repeating deliberately, can carry example .first step, create new variable measuring difference mortality20 mortality16. Make sure increases positive decreases negative.sample mean differences mortality rates, variable diff?sample size 15 small. appropriate conduct t-test? ? ?Find whether difference mortality rates significantly different zero.Draw graph depicts direction alternative hypothesis p-value. Try look lecture slides.Suppose Scottish Government claims mortality rates decreased. Test claim., draw graph depicts direction alternative hypothesis p-value. Try look lecture slides.Drawing results Exercises 5 7, reason p-value obtain tested hypothesis mortality rates increased waves 2016 2020.","code":""},{"path":"causality-and-consolidation.html","id":"causality","chapter":"Causality and Consolidation","heading":"Causality","text":"Identify elements symmetry asymmetry setup case study.Consider Figure 13 lecture. aspects establishing causality case study addressed? missing?\nFigure 13: Causality Framework\n","code":""},{"path":"causality-and-consolidation.html","id":"solutions-2","chapter":"Causality and Consolidation","heading":"Solutions","text":"can find Solutions Downloads Section.","code":""},{"path":"homework-for-week-7.html","id":"homework-for-week-7","chapter":"Homework for Week 7","heading":"Homework for Week 7","text":"Finish working worksheet.Add note underneath code chunk RScript (starting line #), translating code plain English.Read required literature week 7.Work week’s flashcards familiarise relevant R functions.Find example NEW function apply R ensure works.Work Reading Week Taks.coming seminar, encourage work Methods, Methods, Methods Section Week 7. take application cross-tabulations R.","code":""},{"path":"glossary-4.html","id":"glossary-4","chapter":"Glossary","heading":"Glossary","text":" \nTable 7: Glossary Week 5\n ","code":""},{"path":"flashcards-4.html","id":"flashcards-4","chapter":"Flashcards","heading":"Flashcards","text":"\n\n \n\n\n \n\n\n \n","code":""},{"path":"reading-week.html","id":"reading-week","chapter":"Reading Week","heading":"Reading Week","text":"Reading week institutionalised holiday, expect put 10 hours work module course week. suggestions activities fill 10 hours:Catch readingRevise material Weeks 1-5, switch bivariate multivariate analysis Week 7.Go worksheets Weeks 1-5 make sure top things R.Revise R functions point. created Reading Week Consolidation Flashcard Section .","code":""},{"path":"methods-methods-methods.html","id":"methods-methods-methods","chapter":"Methods, Methods, Methods","heading":"Methods, Methods, Methods","text":"coming weeks, find section Companion help apply material cover lecture R. contain RScript preliminary data preparation. actual part introducing method, certainly encouraged read try understand .sections work American National Election Studies (ANES), precise pilot survey conducted 2020 presidential election. can download required data set following link. actual data set available .","code":""},{"path":"methods-methods-methods.html","id":"data-prep","chapter":"Methods, Methods, Methods","heading":"Data Prep","text":"Place ANES data folder using working directory session. Open “Code Data Preparation” , copy RScript. Remember adjust working directory setwd() command beginning. run RScript ready proceed video.can copy code page hovering code chunk clicking icon top-right hand corner. can paste RScript.","code":"\n######################################\n# MMM - Week 1 - Data Preparation\n######################################\n\n\n# Set WD\nsetwd()\n\n# Load packages\n\nlibrary(tidyverse)\n\n# Load data set\n\nanes <- read_csv(\"anes.csv\")\n\n# Get rid of missing values for variables used in analysis today\n\n## 999 is equivalent to NA, so needs to be recoded\nanes$fttrump1 <- with(anes, replace(fttrump1, fttrump1 == 999, NA)) \n\nanes <- filter(anes, \n               !is.na(fttrump1),\n               !is.na(sex))\n\n# turn support for Trump `fttrump1` into ordered factor with three levels\n\nanes <- anes %>% \n  mutate(trump=\n           ordered(\n             cut(fttrump1, breaks=c(0, 33, 66, 100), \n                 labels=c(\"low\",\"medium\",\"high\"))))\n\n# Label variable `sex`\nanes$sex <- factor(anes$sex)\n\nanes <- anes %>% \n  mutate(sex=\n           recode(sex,\"1\"=\"Male\",\n                  \"2\"=\"Female\"))\n\n# save data set for use in video\n\nwrite.csv(anes, \"anes_week1.csv\")"},{"path":"methods-methods-methods.html","id":"video-and-rscript","chapter":"Methods, Methods, Methods","heading":"Video and RScript","text":"can find video introducing week’s method way worked example . can also access code typing video “Code Data Analysis” section. encourage type , though, code tends better sink depths brain 😉Cross Tabulations R\n","code":"\n######################################\n# MMM - Week 1 - Crosstabulations\n######################################\n\n# Set WD\nsetwd()\n\n# Load packages\n\nlibrary(tidyverse)\n\n# Load data set\n\nanes <- read_csv(\"anes_week1.csv\")\nanes$sex <- as.factor(anes$sex)\nanes$trump <- as.factor(anes$trump)\n\n# Tabulate relationship between sex and support for Trump\n\ntable(anes$sex,anes$trump)\n\nprop.table(table(anes$sex,anes$trump))\n\nprop.table(table(anes$sex,anes$trump), margin = 1)\n\n# save table for analysis\n\ntrumpsex <- table(anes$sex,anes$trump)\n\ntrumpsex\n\nxsq <- chisq.test(trumpsex, correct=FALSE)\n\nxsq\n\n# display observed and expected values\n\nxsq$expected\n\nxsq$observed"},{"path":"bivariate-methods.html","id":"bivariate-methods","chapter":"Bivariate Methods","heading":"Bivariate Methods","text":"","code":""},{"path":"bivariate-methods.html","id":"self-assessment-questions-3","chapter":"Bivariate Methods","heading":"Self-Assessment Questions12","text":"need test statistical significance?Given example one-sided, two-sided test significance.Can use continuous variables cross-tabulations?dependent independent variable correlation analysis?Consider causality framework Week 5. extent () correlation (b) cross-tabulations able establish causality?Please stop don’t go beyond point compared notes answers.","code":""},{"path":"bivariate-methods.html","id":"calculations-by-hand","chapter":"Bivariate Methods","heading":"Calculations by Hand","text":"given example cross-tabulation lecture. Consider following Table:  Calculate Expected Values fill following table:  Calculate \\(\\chi^{2}\\)-valueHow many degrees freedom table ? ?Using \\(\\chi^2\\) Table, p-value?mode transport year study independent population?","code":""},{"path":"bivariate-methods.html","id":"applied-exercises-in-r-core","chapter":"Bivariate Methods","heading":"Applied Exercises in R (Core)","text":"Open European Social Survey data, wave 9. Name conveniently attach itUnivariate Analysis (revising weeks 1-2)\nIdentify explore briefly variables respondents’ happiness, subjective health, age household’s income (going look relationships later)\nvalues income variable mean?\nmode ‘age’?\nTry write function automatically determines mode variable (advanced, don’t worry beats . discuss seminar.)\nCheck purpose function round (?round) , relevant, apply appropriately results now onward\nCalculate means, variances standard deviations relevant\nFind suitable plotting function four variables\nIdentify explore briefly variables respondents’ happiness, subjective health, age household’s income (going look relationships later)values income variable mean?mode ‘age’?Try write function automatically determines mode variable (advanced, don’t worry beats . discuss seminar.)Check purpose function round (?round) , relevant, apply appropriately results now onwardCalculate means, variances standard deviations relevantFind suitable plotting function four variablesCrosstabulations\nsuspect relationship health happiness. State null alternative hypothesis. Take care correctly specify dependent independent variable.\nCross-tabulate health happiness, using table function (search ‘?’ needed)\nApply ‘addmargins’ function previous formula\nCan read results? Can interpret ?\nDisplay bivariate plot (search ‘?’ needed). kind plot get? help reading interpreting?\nConvert table percentages. can use function ‘cprop’ ‘lprop’ package ‘questionr’ (can install new package menu “Tools” RStudio). Interpret result. Improve table much can.\nConduct Chi2 test significance interpret result.\nReorder levels Health using ‘factor’ function levels argument. display cross-tabulation .\nrelationship still statistically significant?\nsuspect relationship health happiness. State null alternative hypothesis. Take care correctly specify dependent independent variable.Cross-tabulate health happiness, using table function (search ‘?’ needed)Apply ‘addmargins’ function previous formulaCan read results? Can interpret ?Display bivariate plot (search ‘?’ needed). kind plot get? help reading interpreting?Convert table percentages. can use function ‘cprop’ ‘lprop’ package ‘questionr’ (can install new package menu “Tools” RStudio). Interpret result. Improve table much can.Conduct Chi2 test significance interpret result.Reorder levels Health using ‘factor’ function levels argument. display cross-tabulation .relationship still statistically significant?Correlation\nCalculate Pearson correlation health happiness (need work cases positive values variables, search help file )\nresult confirm previous conclusion?\ncorrelation coefficient statistically significant? mean?\nCalculate Pearson correlation health happiness (need work cases positive values variables, search help file )result confirm previous conclusion?correlation coefficient statistically significant? mean?Application\nForm null und alternative hypotheses relationship \nhappiness household income\nhappiness age\n\nRepeat crosstabulation correlation exercises two pairs variables test hypotheses.\nForm null und alternative hypotheses relationship \nhappiness household income\nhappiness age\nhappiness household incomehappiness ageRepeat crosstabulation correlation exercises two pairs variables test hypotheses.","code":""},{"path":"bivariate-methods.html","id":"applied-exercises-in-r-going-further","chapter":"Bivariate Methods","heading":"Applied Exercises in R (Going Further)","text":"lot choose week, take pick. need . Aim two sections.","code":""},{"path":"bivariate-methods.html","id":"section-1","chapter":"Bivariate Methods","heading":"Section 1","text":"Use ‘prop.table’ function look happiness health comparison genders.Compare genders precisely possible.health drive happiness men women?Identify two countries lowest highest happinessCompare happiness distributions two countriesWhat benefit distributions compared just looking means?","code":""},{"path":"bivariate-methods.html","id":"section-2","chapter":"Bivariate Methods","heading":"Section 2","text":"section use Wave 7 (2014). Name conveniently attach .Calculate Body Mass Index variable BMI=weight/height.Compare mean standard deviation BMI UK SpainApply ‘t.test’ function test difference two means (note now two-sample t-test)inhabitants one country significantly better BMI? know ?","code":""},{"path":"bivariate-methods.html","id":"section-3","chapter":"Bivariate Methods","heading":"Section 3","text":"section use Wave 7 (2014). Name conveniently attach .Plot age respondents completed full-time education fathers (note variables valid UK sample).might outlying values – can see ?Plot , excluding outlying valuesIs significant link fathers children regarding variable?significant link mothers children?links, , stronger sons daughters? Can interpret?","code":""},{"path":"bivariate-methods.html","id":"solutions-3","chapter":"Bivariate Methods","heading":"Solutions","text":"can find Solutions Downloads Section.","code":""},{"path":"homework-for-week-8.html","id":"homework-for-week-8","chapter":"Homework for Week 8","heading":"Homework for Week 8","text":"Finish working worksheet.Add note underneath code chunk RScript (starting line #), translating code plain English.Read required literature week 8.Work week’s flashcards familiarise relevant R functions.Find example NEW function apply R ensure works.coming seminar, encourage work Methods, Methods, Methods Sections Week 8, starting Bivariate Regression (three different ones). take relevant components regression analysis R.","code":""},{"path":"glossary-5.html","id":"glossary-5","chapter":"Glossary","heading":"Glossary","text":" \nTable 8: Glossary Week 7\n ","code":""},{"path":"flashcards-5.html","id":"flashcards-5","chapter":"Flashcards","heading":"Flashcards","text":"\n\n \n\n\n \n\n\n \n","code":""},{"path":"mmm-bivariate-regression.html","id":"mmm-bivariate-regression","chapter":"MMM – Bivariate Regression","heading":"MMM – Bivariate Regression","text":"week starting conduct linear regression analysis R.Just week 7 working American National Election Studies (ANES), precise pilot survey conducted 2020 presidential election. haven’t already done , register ANES order download data set. , please follow link.","code":""},{"path":"mmm-bivariate-regression.html","id":"data-prep-1","chapter":"MMM – Bivariate Regression","heading":"Data Prep","text":"Place ANES data folder using working directory session. Open “Code Data Preparation” , copy RScript. Remember adjust working directory setwd() command beginning. run RScript ready proceed video.","code":"\n######################################\n# MMM - Week 4 - Data Preparation\n######################################\n\n\n# Set WD\nsetwd()\n\n# Load packages\n\nlibrary(tidyverse)\n\n# Load data set\n\nanes <- read_csv(\"anes.csv\")\n\n# Get rid of missing values for variables used in analysis today\n\n## 999 is equivalent to NA, so needs to be recoded\nanes$fttrump1 <- with(anes, replace(fttrump1, fttrump1 == 999, NA)) \nanes$income <- with(anes, replace(income, income == 99, NA)) \n\nanes <- filter(anes, \n               !is.na(fttrump1),\n               !is.na(age),\n               !is.na(income))\n\n# Turn income variable into a numerical variable with mid-points of each level\n\nanes$income <- factor(anes$income)\ntable(anes$income)\nanes <- anes %>%\n  mutate(income_fac = recode(income,\n                             '1'= \"2500\",\n                             '2'= \"7499.5\",\n                             '3'= \"12499.5\",\n                             '4'= \"17499.5\",                       \n                             '5'= \"22499.5\",\n                             '6'= \"27499.5\",\n                             '7'= \"32499.5\",\n                             '8'= \"37499.5\",\n                             '9'= \"42499.5\",\n                             '10'= \"47499.5\",\n                             '11'= \"52499.5\",\n                             '12'= \"57499.5\",\n                             '13'= \"62499.5\",\n                             '14'= \"67499.5\",\n                             '15'= \"72499.5\",\n                             '16'= \"77499.5\",\n                             '17'= \"82499.5\",\n                             '18'= \"87499.5\",\n                             '19'= \"92499.5\",\n                             '20'= \"97499.5\",\n                             '21'= \"112499.5\",\n                             '22'= \"137499.5\",\n                             '23'= \"162499.5\",\n                             '24'= \"187499.5\",\n                             '25'= \"224999.5\",\n                             '26'= \"500000\"))\n\nanes$inc <- as.numeric(as.character(anes$income_fac))\n\n# save data set for use in video\n\nwrite.csv(anes, \"anes_week4.csv\")"},{"path":"mmm-bivariate-regression.html","id":"video-and-rscript-1","chapter":"MMM – Bivariate Regression","heading":"Video and RScript","text":"can find video introducing week’s method way worked example . can also access code typing video “Code Data Analysis” section. encourage type , though, code tends better sink depths brain 😉Bivariate Regression R","code":"\n######################################\n# MMM - Week 4 - Bivariate Regression\n######################################\n\n# Set WD\nsetwd()\n\n# Load packages\n\nlibrary(tidyverse)\n\n# Load data set\n\nanes <- read_csv(\"anes_week4.csv\")\n\n# Visualisation\n############################\n\nggplot(anes, aes(x = inc, y = fttrump1)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\n\n# Regression\n############################\n\nmodel1 <- lm(fttrump1 ~ inc, data = anes)\n\nmodel1"},{"path":"mmm-model-fit.html","id":"mmm-model-fit","chapter":"MMM – Model Fit","heading":"MMM – Model Fit","text":"Section explore measure model fit, -called R-Squared. Discover obtain R section.Just week 4 working American National Election Studies (ANES), precise pilot survey conducted 2020 presidential election. haven’t already done , register ANES order download data set. , please follow link.","code":""},{"path":"mmm-model-fit.html","id":"data-prep-2","chapter":"MMM – Model Fit","heading":"Data Prep","text":"Place ANES data folder using working directory session. Open “Code Data Preparation” , copy RScript. Remember adjust working directory setwd() command beginning. run RScript ready proceed video.","code":"\n######################################\n# MMM - Week 5 - Data Preparation\n######################################\n\n\n# Set WD\nsetwd()\n\n# Load packages\n\nlibrary(tidyverse)\n\n# Load data set\n\nanes <- read_csv(\"anes.csv\")\n\n# Get rid of missing values for variables used in analysis today\n\n## 999 is equivalent to NA, so needs to be recoded\nanes$fttrump1 <- with(anes, replace(fttrump1, fttrump1 == 999, NA)) \nanes$income <- with(anes, replace(income, income == 99, NA)) \n\nanes <- filter(anes, \n               !is.na(fttrump1),\n               !is.na(age),\n               !is.na(income))\n\n# Turn income variable into a numerical variable with mid-points of each level\n\nanes$income <- factor(anes$income)\ntable(anes$income)\nanes <- anes %>%\n  mutate(income_fac = recode(income,\n                             '1'= \"2500\",\n                             '2'= \"7499.5\",\n                             '3'= \"12499.5\",\n                             '4'= \"17499.5\",                       \n                             '5'= \"22499.5\",\n                             '6'= \"27499.5\",\n                             '7'= \"32499.5\",\n                             '8'= \"37499.5\",\n                             '9'= \"42499.5\",\n                             '10'= \"47499.5\",\n                             '11'= \"52499.5\",\n                             '12'= \"57499.5\",\n                             '13'= \"62499.5\",\n                             '14'= \"67499.5\",\n                             '15'= \"72499.5\",\n                             '16'= \"77499.5\",\n                             '17'= \"82499.5\",\n                             '18'= \"87499.5\",\n                             '19'= \"92499.5\",\n                             '20'= \"97499.5\",\n                             '21'= \"112499.5\",\n                             '22'= \"137499.5\",\n                             '23'= \"162499.5\",\n                             '24'= \"187499.5\",\n                             '25'= \"224999.5\",\n                             '26'= \"500000\"))\n\nanes$inc <- as.numeric(as.character(anes$income_fac))\n\n# save data set for use in video\n\nwrite.csv(anes, \"anes_week5.csv\")"},{"path":"mmm-model-fit.html","id":"video-and-rscript-2","chapter":"MMM – Model Fit","heading":"Video and RScript","text":"can find video introducing week’s method way worked example . can also access code typing video “Code Data Analysis” section. encourage type , though, code tends better sink depths brain 😉Model Fit Regression R","code":"\n######################################\n# MMM - Week 5 - Model Fit\n######################################\n\n# Set WD\nsetwd()\n\n# Load packages\n\nlibrary(tidyverse)\n\n# Load data set\n\nanes <- read_csv(\"anes_week5.csv\")\n\n# Visualisation\n############################\n\nggplot(anes, aes(x = inc, y = fttrump1)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\n\n# Regression\n############################\n\nmodel1 <- lm(fttrump1 ~ inc, data = anes)\n\nmodel1\n\nsummary(model1)"},{"path":"mmm-significance-testing.html","id":"mmm-significance-testing","chapter":"MMM – Significance Testing","heading":"MMM – Significance Testing","text":"Now delve little deeper output linear regression analysis R ascertain whether coefficients actually statistically different zero, put less technically whether influence.Just last week working American National Election Studies (ANES), precise pilot survey conducted 2020 presidential election. haven’t already done , register ANES order download data set. , please follow link.","code":""},{"path":"mmm-significance-testing.html","id":"data-prep-3","chapter":"MMM – Significance Testing","heading":"Data Prep","text":"Place ANES data folder using working directory session. Open “Code Data Preparation” , copy RScript. Remember adjust working directory setwd() command beginning. run RScript ready proceed video.","code":"\n######################################\n# MMM - Week 7 - Data Preparation\n######################################\n\n\n# Set WD\nsetwd()\n\n# Load packages\n\nlibrary(tidyverse)\n\n# Load data set\n\nanes <- read_csv(\"anes.csv\")\n\n# Get rid of missing values for variables used in analysis today\n\n## 999 is equivalent to NA, so needs to be recoded\nanes$fttrump1 <- with(anes, replace(fttrump1, fttrump1 == 999, NA)) \nanes$income <- with(anes, replace(income, income == 99, NA)) \n\nanes <- filter(anes, \n               !is.na(fttrump1),\n               !is.na(age),\n               !is.na(income))\n\n# Turn income variable into a numerical variable with mid-points of each level\n\nanes$income <- factor(anes$income)\ntable(anes$income)\nanes <- anes %>%\n  mutate(income_fac = recode(income,\n                             '1'= \"2500\",\n                             '2'= \"7499.5\",\n                             '3'= \"12499.5\",\n                             '4'= \"17499.5\",                       \n                             '5'= \"22499.5\",\n                             '6'= \"27499.5\",\n                             '7'= \"32499.5\",\n                             '8'= \"37499.5\",\n                             '9'= \"42499.5\",\n                             '10'= \"47499.5\",\n                             '11'= \"52499.5\",\n                             '12'= \"57499.5\",\n                             '13'= \"62499.5\",\n                             '14'= \"67499.5\",\n                             '15'= \"72499.5\",\n                             '16'= \"77499.5\",\n                             '17'= \"82499.5\",\n                             '18'= \"87499.5\",\n                             '19'= \"92499.5\",\n                             '20'= \"97499.5\",\n                             '21'= \"112499.5\",\n                             '22'= \"137499.5\",\n                             '23'= \"162499.5\",\n                             '24'= \"187499.5\",\n                             '25'= \"224999.5\",\n                             '26'= \"500000\"))\n\nanes$inc <- as.numeric(as.character(anes$income_fac))\n\n# save data set for use in video\n\nwrite.csv(anes, \"anes_week7.csv\")"},{"path":"mmm-significance-testing.html","id":"video-and-rscript-3","chapter":"MMM – Significance Testing","heading":"Video and RScript","text":"can find video introducing week’s method way worked example . can also access code typing video “Code Data Analysis” section. encourage type , though, code tends better sink depths brain 😉Significance Test Coefficients R","code":"\n######################################\n# MMM - Week 7 - Hypothesis Testing\n######################################\n\n# Set WD\nsetwd()\n\n# Load packages\n\nlibrary(tidyverse)\n\n# Load data set\n\nanes <- read_csv(\"anes_week8.csv\")\n\n# Visualisation\n############################\n\nggplot(anes, aes(x = inc, y = fttrump1)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\n\n# Regression\n############################\n\nmodel1 <- lm(fttrump1 ~ inc, data = anes)\n\nmodel1\n\nsummary(model1)"},{"path":"bivariate-regression.html","id":"bivariate-regression","chapter":"Bivariate Regression","heading":"Bivariate Regression","text":"","code":""},{"path":"bivariate-regression.html","id":"self-assessment-questions-4","chapter":"Bivariate Regression","heading":"Self-Assessment Questions13","text":"regression ?error term regression?OLS fit regression line?need measure assess goodness fit?Consider causality framework Week 5. extent bivariate regression helpful establish causality?Please stop don’t go beyond point compared notes answers.","code":""},{"path":"bivariate-regression.html","id":"exercises-core","chapter":"Bivariate Regression","heading":"Exercises – Core","text":"","code":""},{"path":"bivariate-regression.html","id":"conceptual","chapter":"Bivariate Regression","heading":"Conceptual","text":"Recall :\\[\\begin{equation}\\label{eq:beta1est}\n\\hat{\\beta_{0}} =  \\bar{y} - \\hat{\\beta_{1}}\\bar{x}\n\\end{equation}\\] \n \\[\\begin{equation}\n\\hat{\\beta_{1}} = \\dfrac{\\Sigma_{=1}^{N} (x_{}-\\bar{x})(y_{}-\\bar{y})}{\\Sigma_{=1}^{N} (x_{} - \\bar{x})^{2}}\n\\end{equation}\\]Now consider following data set: \nTable 9: Regression Data Set\n Assuming regression model type \\(y_{}=\\beta_{0}+ \\beta_{1}x_{}+\\epsilon_{}\\), calculate estimates \\(\\beta_{0}\\) \\(\\beta_{1}\\) hand (yes, read correctly). Use Table guide required intermediary calculations.Specify SRF interpret estimates \\(\\beta_{0}\\) \\(\\beta_{1}\\).Determine whether slope coefficient significant 95% confidence level.Calculate coefficient determination, \\(r^{2}\\), \\(\\hat{y}_{}= -53.1 + 39.7 x_{}\\). \nTable 10: Regression Data Set\n ","code":""},{"path":"bivariate-regression.html","id":"applied","chapter":"Bivariate Regression","heading":"Applied","text":"applied exercises using data set london_exercises. analyse patterns crime London14. dataset contains several variables London wards, describing, amongst things, demographics population number crimes committed 2015. full codebook provided following Table: \nTable 11: Codebook london_exercises Data Set\n data taken London Data Store (2013).Examine London data. hypothesis tested using variables contained dataset?Crime rate defined number crimes committed per 1,000 people given area.\nEvaluate variable’s distribution using histogram summary statistics.\nwards crimes committed ? Find names wards crime rate higher 99th percentile variable’s distribution.\nEvaluate variable’s distribution using histogram summary statistics.wards crimes committed ? Find names wards crime rate higher 99th percentile variable’s distribution.London divided 32 Boroughs City London. Examine variation crime Borough level.\nCalculate crime rate Boroughs.\nPresent Borough-level crime rates using table bar chart, Borough order descending crime rate.\nCalculate crime rate Boroughs.Present Borough-level crime rates using table bar chart, Borough order descending crime rate.Unemployment rate, defined ratio people full time employment population working age often said related crime.\nGenerate unemployment rate variable wards.\nExamine distribution unemployment rate similar manner Exercise 2.\nCreate scatter plot relationship unemployment crime. Make sure choose right axis variables label axes correctly. Interpret results.\nCalculate correlation coefficient two variables interpret value.\nGenerate unemployment rate variable wards.Examine distribution unemployment rate similar manner Exercise 2.Create scatter plot relationship unemployment crime. Make sure choose right axis variables label axes correctly. Interpret results.Calculate correlation coefficient two variables interpret value.Estimate regression model relationship unemployment rate crime rate.\nInterpret following:\nintercept significance.\nslope significance.\ndistribution residuals. (Use histogram).\n\\(R^2\\) statistic.\n\nAdd regression line scatter plot Exercise 4.\nCalculate 95% CI coefficient slope model.\nUsing model, predict value crime rate hypothetical ward unemployment rate \\(0.4\\).\nInterpret following:\nintercept significance.\nslope significance.\ndistribution residuals. (Use histogram).\n\\(R^2\\) statistic.\nintercept significance.slope significance.distribution residuals. (Use histogram).\\(R^2\\) statistic.Add regression line scatter plot Exercise 4.Calculate 95% CI coefficient slope model.Using model, predict value crime rate hypothetical ward unemployment rate \\(0.4\\).can hypothesised ward higher median household income lower rate crime compared ward lower median household income.\nRun regression model testing hypothesis.\nInterpret coefficients, significance levels, \\(R^2\\) model.\nProduce scatter plot add regression line.\nconclusions can draw model plot regards hypothesis?\nRun regression model testing hypothesis.Interpret coefficients, significance levels, \\(R^2\\) model.Produce scatter plot add regression line.conclusions can draw model plot regards hypothesis?mean age ward can said influence rate crime ward.\nCome hypothesis relationship mean age ward rate crime ward. Briefly justify chose hypothesis.\nRun regression model testing hypothesis interpret results model. interpretation suggest hypothesis?\nCome hypothesis relationship mean age ward rate crime ward. Briefly justify chose hypothesis.Run regression model testing hypothesis interpret results model. interpretation suggest hypothesis?can hypothesised ward larger number benefit recipients higher rate crime compared ward fewer benefit recipients.%8\nExplain reasons might case.\nRun regression model testing hypothesis interpret results model. interpretation suggest hypothesis?\nProduce scatter plot add regression line.\nCompare regression model models Exercises 6 7. better able explain crime rate ward ?\nExplain reasons might case.Run regression model testing hypothesis interpret results model. interpretation suggest hypothesis?Produce scatter plot add regression line.Compare regression model models Exercises 6 7. better able explain crime rate ward ?","code":""},{"path":"bivariate-regression.html","id":"going-further-in-r","chapter":"Bivariate Regression","heading":"Going Further in R","text":"London Boroughs classified either ‘Inner’ ‘Outer’ boroughs.\nRecreate scatter plot Question 2 Core Exercises, different colours inner outer boroughs subsetting data wards crime rate 500.\nShow observations inner boroughs red, th outer boroughs blue.\nAdd line best fit plot, retaining red blue inner outer boroughs, respectively.\nEstimate regression model relationship unemployment rate crime rate inner outer boroughs.\nCompare coefficients two models, can interpret ?\nCompare interpret \\(R^2\\) statistics. unemployment better explain crime inner outer boroughs?\nUsing models estimated predict crime rate inner outer borough given ward unemployment rate \\(0.45\\).\n\nRecreate scatter plot Question 2 Core Exercises, different colours inner outer boroughs subsetting data wards crime rate 500.Show observations inner boroughs red, th outer boroughs blue.Add line best fit plot, retaining red blue inner outer boroughs, respectively.Estimate regression model relationship unemployment rate crime rate inner outer boroughs.\nCompare coefficients two models, can interpret ?\nCompare interpret \\(R^2\\) statistics. unemployment better explain crime inner outer boroughs?\nUsing models estimated predict crime rate inner outer borough given ward unemployment rate \\(0.45\\).\nCompare coefficients two models, can interpret ?Compare interpret \\(R^2\\) statistics. unemployment better explain crime inner outer boroughs?Using models estimated predict crime rate inner outer borough given ward unemployment rate \\(0.45\\).","code":""},{"path":"case-study-1.html","id":"case-study-1","chapter":"Case Study15","heading":"Case Study15","text":"","code":""},{"path":"case-study-1.html","id":"load-packages-and-data","chapter":"Case Study15","heading":"Load Packages and Data","text":"starting, need load libraries install packages already installed. exercises using following packages:havenggplot2modelsummaryWe using london.csv data set lecture, different independent variable time. particular interest: \nTable 12: london Codebook\n Data taken House Commons Library (n.d.), GOV.UK (2013), London Data Store (2010). Set working directory load data.","code":""},{"path":"case-study-1.html","id":"inspect-your-data","chapter":"Case Study15","heading":"Inspect your data","text":"can use several basic functions. dataset contain many variables, can start using names(), str(), etc.","code":""},{"path":"case-study-1.html","id":"preliminary-analysis","chapter":"Case Study15","heading":"Preliminary Analysis","text":"Let’s say want look relationship income deprivation affecting children GCSE scores. two variables , respectively, idaci gcse.Now, formulate working (alternative) null hypothesis. Write .H\\(\\pmb{_0}\\):H\\(\\pmb{_1}\\):dependent variable?Run frequency table idaci variable. distribution make sense? /?variable. guess level measurement.","code":""},{"path":"case-study-1.html","id":"visualisation-1","chapter":"Case Study15","heading":"Visualisation","text":"Let’s start visualisation relationship two variables. best way visualise relationship considering level measurement variables?Hint: Probably scatterplot, right? , use scatterplot visualise relationship add regression line.can use ggplot, also base R plot() function.Improve graph :Adding regression line.Adding relevant title, also possibly subtitle.Adding axes labels making readable.\nFigure 14: Impoact Deprivation GCSE Scores\n","code":""},{"path":"case-study-1.html","id":"visualisation-2.0","chapter":"Case Study15","heading":"Visualisation 2.0","text":"Now, draw vertical horizontal line corresponding mean variables using geom_hline geom_vline. can thus check regression line passes mean X Y. (see: https://www.rdocumentation.org/packages/ggplot2/versions/0.9.1/topics/geom_hline).can improve scatterplot using series arguments (e.g., alpha) geom_point() function ggplot. Try improve Aesthetics scatterplot playing alpha, instance. (see: https:\n//www.rdocumentation.org/packages/ggplot2/versions/3.4.0/topics/geom_point).","code":""},{"path":"case-study-1.html","id":"saving-the-scatterplot","chapter":"Case Study15","heading":"Saving the Scatterplot","text":"can save graph .png, .JPG (even .pdf) can import word document. Although many way use R output, saving graph might sometimes useful.Use function ggsave() save scatterplot. , tons examples online, google .Hint: first need store graph object.Hint 2: file end working directory.","code":""},{"path":"case-study-1.html","id":"regression-analysis-yes-finally","chapter":"Case Study15","heading":"Regression Analysis (yes, finally)","text":"Now can finally run linear regression gcse outcome variable idaci predictor using lm() function. Store results object called model visualise regression output using summary().can also extract specific blocks output table. One way use brackets [] summary() function. example summary()[8]. Try extract block Coefficients table, like :","code":"\n# Store the results in an object called model #\nmodel<-lm(gcse ~ idaci, london)\n# Visualise the regression output using summary() #\nsummary(model)\nCall:\nlm(formula = gcse ~ idaci, data = london)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-6.4921 -2.5321 -0.1722  2.7077  7.7815 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 45.852958   0.657251  69.765  < 2e-16 ***\nidaci        0.019765   0.002894   6.831  2.4e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.317 on 71 degrees of freedom\nMultiple R-squared:  0.3965,    Adjusted R-squared:  0.388 \nF-statistic: 46.66 on 1 and 71 DF,  p-value: 2.398e-09$coefficients\n              Estimate Std. Error   t value     Pr(>|t|)\n(Intercept) 45.8529580 0.65725150 69.764707 3.767825e-67\nidaci        0.0197651 0.00289364  6.830532 2.397995e-09"},{"path":"case-study-1.html","id":"interpretation","chapter":"Case Study15","heading":"Interpretation","text":"Interpret results, starting model evaluation.p-value F-statistics statistically significant? discussing following lectures.much variation outcome variable model explain? tell us model?’s value slope? mean?’s value intercept? interpret ? statistically significant? mean practice?Interpret results (plain language) referring hypothesis formulated .","code":""},{"path":"case-study-1.html","id":"exporting-the-results","chapter":"Case Study15","heading":"Exporting the Results","text":"graphs, can also export save results regression model Word table. can use ‘modelsummary’ package.Just like writing shopping list, start creating list models want modelsummary produce table. can merely list names objects models stored, can give specific names appear column titles table. addition means must, sometimes might wish give models particular name, example used different methods estimation, different components theory, etc. table creating , wish distinguish bivariate multivariate models. default, modelsummary just numbers models ascending order.simple step already sufficient produce – admittedly somewhat crude – results table. load modelsummary package use previously defined list models argument modelsummary() function:Execute code chunks go Section, can see alterations make table real-time.table vast improvement raw R output receive calling summary(model1). far finished. One characteristic conspicuously absent assessment statistical significance. model summaries kind information usually provided form asterisks symbols next respective coefficient. can add simply adding option stars=TRUE code.Next modification stub. stub leftmost column name indicators coefficients presented.stub, “[]bbreviate nothing. never ever ever use computer variable names stand concepts. personal code words convey meaning readers.” (Stimson, n.d., p. 10) Following advice, let us add proper labels independent variables.let modelsummary know replace variable name, create -called coefficient map. really just character vector follows “-” logic rows. example 'age'='Age' replaces variable name age label Age. need variables used models. storing vecor called cm stands coefficient map.next step easy, need feed coefficient map modelsummary code option coef_map=cm:personal thing, also like show label dependent variable results tables. just feel incomplete without information. default achieve modelsummary need use little trick.want add first row, second columm, text . requires us alter style table slightly. modelsummary uses another package called tinytable style output. load package library(tinytable) instruct R place text want .Lastly, let us tackle model fit statistics. default, modelsummary prints whole festival bottom section table, want concentrate R\\(^2\\).produce table:Table 13:  Regression ModelsYou can export tables use MS Word, Apple Pages. able export full table, point specifying options tinytable |>. probably good reason start working Markdown LaTeXBut happy caveat, following code render table MS Word document (output=\"table.docx\") placed working directory.","code":"\nmodels <- list(\n  \"Bivariate\"    = model\n)\nlibrary(modelsummary)\nmodelsummary(models)\nmodelsummary(models,\n             stars = TRUE)\ncm <- c('idaci'    = 'Income Deprivation Affecting Children Index',\n        '(Intercept)' = 'Intercept')\nmodelsummary(models,\n             stars = TRUE,\n             coef_map = cm)\nlibrary(tinytable)\nmodelsummary(models,\n             stars = TRUE,\n             coef_map = cm)|>\n  group_tt(j = list(\"Dependent Variable: GCSE Score\" = 2))\nmodelsummary(models,\n             stars = TRUE,\n             coef_map = cm,\n             gof_omit = 'DF|Deviance|Log.Lik|F|AIC|BIC|RMSE')|>\n  group_tt(j = list(\"Dependent Variable: GCSE Score\" = 2))\nmodelsummary(models,\n             stars = TRUE,\n             coef_map = cm,\n             gof_omit = 'AIC|BIC|Log.Lik|F|RMSE',\n             add_rows = rows,\n             notes = list('This is a long and rather pointless \n                          note to demonstrate formatting.'),\n             output = \"table.docx\")"},{"path":"case-study-1.html","id":"comparing-models","chapter":"Case Study15","heading":"Comparing Models","text":"can now run another regression model . Compare original model new one. know independent variable better job explaining dependent variable?","code":""},{"path":"case-study-1.html","id":"causality-1","chapter":"Case Study15","heading":"Causality","text":"Consider causality framework Week 5. extent case study established causality? missing framework?","code":""},{"path":"homework-for-week-9.html","id":"homework-for-week-9","chapter":"Homework for Week 9","heading":"Homework for Week 9","text":"Finish working worksheet.Complete Case Study.Add note underneath code chunk RScript (starting line #), translating code plain English.Read required literature week 9.Work week’s flashcards familiarise relevant R functions.Find example NEW function apply R ensure works.coming seminar, encourage work Methods, Methods, Methods Section Week 9. take relevant components regression analysis R.","code":""},{"path":"homework-for-week-9.html","id":"solutions-4","chapter":"Homework for Week 9","heading":"Solutions","text":"can find Solutions Downloads Section.","code":""},{"path":"glossary-6.html","id":"glossary-6","chapter":"Glossary","heading":"Glossary","text":" \nTable 14: Glossary Week 8\n ","code":""},{"path":"flashcards-6.html","id":"flashcards-6","chapter":"Flashcards","heading":"Flashcards","text":"\n\n \n\n\n \n\n\n \n","code":""},{"path":"methods-methods-methods-1.html","id":"methods-methods-methods-1","chapter":"Methods, Methods, Methods","heading":"Methods, Methods, Methods","text":"week extending bivariate regression model approximate real world nothing mono-causal. call multiple regression.Just last week working American National Election Studies (ANES), precise pilot survey conducted 2020 presidential election. haven’t already done , register ANES order download data set. , please follow link.","code":""},{"path":"methods-methods-methods-1.html","id":"data-prep-4","chapter":"Methods, Methods, Methods","heading":"Data Prep","text":"Place ANES data folder using working directory session. Open “Code Data Preparation” , copy RScript. Remember adjust working directory setwd() command beginning. run RScript ready proceed video.","code":"\n######################################\n# MMM - Week 8 - Data Preparation\n######################################\n\n\n# Set WD\nsetwd()\n\n# Load packages\n\nlibrary(tidyverse)\n\n# Load data set\n\nanes <- read_csv(\"anes.csv\")\n\n# Get rid of missing values for variables used in analysis today\n\n## 999 is equivalent to NA, so needs to be recoded\nanes$fttrump1 <- with(anes, replace(fttrump1, fttrump1 == 999, NA)) \nanes$income <- with(anes, replace(income, income == 99, NA)) \n\nanes <- filter(anes, \n               !is.na(fttrump1),\n               !is.na(age),\n               !is.na(income))\n\n# Turn income variable into a numerical variable with mid-points of each level\n\nanes$income <- factor(anes$income)\ntable(anes$income)\nanes <- anes %>%\n  mutate(income_fac = recode(income,\n                             '1'= \"2500\",\n                             '2'= \"7499.5\",\n                             '3'= \"12499.5\",\n                             '4'= \"17499.5\",                       \n                             '5'= \"22499.5\",\n                             '6'= \"27499.5\",\n                             '7'= \"32499.5\",\n                             '8'= \"37499.5\",\n                             '9'= \"42499.5\",\n                             '10'= \"47499.5\",\n                             '11'= \"52499.5\",\n                             '12'= \"57499.5\",\n                             '13'= \"62499.5\",\n                             '14'= \"67499.5\",\n                             '15'= \"72499.5\",\n                             '16'= \"77499.5\",\n                             '17'= \"82499.5\",\n                             '18'= \"87499.5\",\n                             '19'= \"92499.5\",\n                             '20'= \"97499.5\",\n                             '21'= \"112499.5\",\n                             '22'= \"137499.5\",\n                             '23'= \"162499.5\",\n                             '24'= \"187499.5\",\n                             '25'= \"224999.5\",\n                             '26'= \"500000\"))\n\nanes$inc <- as.numeric(as.character(anes$income_fac))\n\n# save data set for use in video\n\nwrite.csv(anes, \"anes_week8.csv\")"},{"path":"methods-methods-methods-1.html","id":"video-and-rscript-4","chapter":"Methods, Methods, Methods","heading":"Video and RScript","text":"can find video introducing week’s method way worked example . can also access code typing video “Code Data Analysis” section. encourage type , though, code tends better sink depths brain 😉Multiple Regression R","code":"\n######################################\n# MMM - Week 8 - Multiple Regression\n######################################\n\n# Set WD\nsetwd()\n\n# Load packages\n\nlibrary(tidyverse)\n\n# Load data set\n\nanes <- read_csv(\"anes_week9.csv\")\n\n\n# Bivariate Regression\n############################\n\nmodel1 <- lm(fttrump1 ~ inc, data = anes)\n\nsummary(model1)\n\nmodel2 <- lm(fttrump1 ~ age, data = anes)\n\nsummary(model2)\n\n# Multiple Regression\n############################\n\nmodel3 <- lm(fttrump1 ~ inc + age, data = anes)\n\nsummary(model3)"},{"path":"multiple-regression.html","id":"multiple-regression","chapter":"Multiple Regression","heading":"Multiple Regression","text":"","code":""},{"path":"multiple-regression.html","id":"group-work-self-reflection","chapter":"Multiple Regression","heading":"Group Work – Self-Reflection16","text":"Compare bivariate regression multiple regression.Give example relationship apply multiple linear regression.interpret partial slope coefficients?interpret adjusted R-Squared regression analysis?Consider causality framework Week 5. extent multiple regression helpful establish causality?Prepare interpret following regression output substantively (coefficients mean, good model fit, etc.) income represents median household income London ward (£), turnout represents turnout 2012 mayoral election (%). Please stop don’t go beyond point compared notes answers.","code":"\nCall:\nlm(formula = turnout ~ income, data = london)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-24.3099  -2.3808   0.5004   3.2679  11.2834 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 1.955e+01  9.861e-01   19.83   <2e-16 ***\nincome      3.720e-04  2.467e-05   15.08   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.594 on 623 degrees of freedom\nMultiple R-squared:  0.2673,    Adjusted R-squared:  0.2661 \nF-statistic: 227.3 on 1 and 623 DF,  p-value: < 2.2e-16"},{"path":"multiple-regression.html","id":"multiple-regression-in-r-guided-example","chapter":"Multiple Regression","heading":"Multiple Regression in R – Guided Example","text":"Download WDI_PO91Q.csv data set. Data taken World Bank (2024), Miller et al. (2022), Marshall & Gurr (2020).Put appropriate working directory seminar create dedicated RScript save working directory.Import data set R:, overview variables available respective label Table 15: \nTable 15: WDI Codebook\n Let’s take example Week 7 back . First re-run regression used back .Interpret coefficients.Interpreting coefficientThe order interpret coefficient follows:significant? , can say influence. insufficient evidence support alternative hypothesis.significant, can interpret size direction according statistical model (example, slope coefficient vs. partial slope coefficient).coefficient mean hypothesis? Look direction. direction predicted hypothesis? evidence support hypothesis. direction inverse, falsified hypothesis, even though significant coefficient.Now use different regressor, say “Urban population (% total)”.Specify null alternative hypotheses.Interpret coefficients.mean hypotheses?want assess influence independent variables together, type:Interpret coefficients.Bear mind interpretation partial slope coefficients!nice, producing overview17 three regressions Table 16:Table 16:  Regression Models 1. \n Drawing learned modelsummary package additional exercises last week, replicate table.slope coefficients changed? ?model explains level GDP best? ?Specify SRF Model 3, paying special attention notation.Now assume, want know whether education bearing level GDP. call:also add joint model:lead results:Table 17:  Regression Models 2. \n Model 5 coefficient literacy turned insignificant. Reproduce results Table 4 find variable takes away significance.Table 18:  Regression Models 3. \n can conclude investigation?can conclude investigation?variable infant effect? conclude ?variable infant effect? conclude ?measurement explains GDP better, life infant?measurement explains GDP better, life infant?Table 19:  Regression Models 4. \n ","code":"\nsetwd(\"~/Warwick/Modules/PO91Q/Seminars/Week 8\")\nwdi <- read.csv(\"WDI_PO91Q.csv\")\nwdi_life <- lm(gdppc ~ lifeexp, data = wdi)\nsummary(wdi_life)\nCall:\nlm(formula = gdppc ~ lifeexp, data = wdi)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-18457  -9877  -4187   4963  78242 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -94306.8    10406.7  -9.062 3.33e-16 ***\nlifeexp       1503.2      144.4  10.412  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 14690 on 167 degrees of freedom\n  (26 observations deleted due to missingness)\nMultiple R-squared:  0.3936,    Adjusted R-squared:   0.39 \nF-statistic: 108.4 on 1 and 167 DF,  p-value: < 2.2e-16\nwdi_urban <- lm(gdppc ~ urban, data = wdi)\nsummary(wdi_urban)\nCall:\nlm(formula = gdppc ~ urban, data = wdi)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-28588 -10681  -3110   6863 152303 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -16983.43    3872.34  -4.386 1.98e-05 ***\nurban          542.03      61.74   8.779 1.42e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 19120 on 176 degrees of freedom\n  (17 observations deleted due to missingness)\nMultiple R-squared:  0.3045,    Adjusted R-squared:  0.3006 \nF-statistic: 77.07 on 1 and 176 DF,  p-value: 1.417e-15\nwdi_joint <- lm(gdppc ~ lifeexp + urban, data = wdi)\nsummary(wdi_joint)\nCall:\nlm(formula = gdppc ~ lifeexp + urban, data = wdi)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-22570  -8825  -2143   5594  74445 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -74786.14   10690.13  -6.996 6.17e-11 ***\nlifeexp       1012.17     172.70   5.861 2.41e-08 ***\nurban          273.74      59.13   4.629 7.37e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 13860 on 166 degrees of freedom\n  (26 observations deleted due to missingness)\nMultiple R-squared:  0.463, Adjusted R-squared:  0.4565 \nF-statistic: 71.55 on 2 and 166 DF,  p-value: < 2.2e-16\nwdi_lit <- lm(gdppc ~ literacy, data = wdi)\nwdi_joint1 <- lm(gdppc ~ lifeexp + urban + literacy, data = wdi)"},{"path":"multiple-regression.html","id":"multiple-regression-in-r-independent-analysis","chapter":"Multiple Regression","heading":"Multiple Regression in R – Independent Analysis","text":"start , please pause let Flo know done. compare notes answers point, make sure right track independent exercises.Use wdi data frame. Set polity5 dependent variable, choose three sensible variables believe influence democracy. Note Polity V Score codes regimes -10 (indicating perfect autocracy) +10 (indicating perfect democracy).State null- alternative hypotheses independent variables chosen.Plot two bivariate models scatter plot (black points) fitted regression line (red). Use base R, ggplot. direction influence agree hypotheses?Run possible regression models, using bottom-strategy. Construct stargazer table present results.Specify Sample Regression Function (SRF) bivariate model (Model ), multivariate model two independent variables (Model B), model using three independent variables (Model C).Interpret intercept one slope coefficients Models , B, C.Interpret model fit measure Models , B, C.model explains democracy best? ?.conclude respect hypotheses stated Exercise 2 analysis?Collate PowerPoint (Keynote) presentation one slide preceding nine points. discuss Week 9.","code":""},{"path":"multiple-regression.html","id":"going-further-1","chapter":"Multiple Regression","heading":"Going Further","text":"Plot scatter plots models two independent variables. Add line best fit, hyperplane best fit appropriate. Use rockchalk package, function plotPlane() 3D plots.","code":""},{"path":"homework-for-week-10.html","id":"homework-for-week-10","chapter":"Homework for Week 10","heading":"Homework for Week 10","text":"Finish working worksheet.Add note underneath code chunk RScript (starting line #), translating code plain English.Read required literature week 10.Work week’s flashcards familiarise relevant R functions.Find example NEW function apply R ensure works.Complete Mock Exam Moodle. go solutions together next week.coming seminar, encourage work Methods, Methods, Methods Section Week 10.","code":""},{"path":"homework-for-week-10.html","id":"solutions-5","chapter":"Homework for Week 10","heading":"Solutions","text":"can find Solutions Downloads Section.","code":""},{"path":"glossary-7.html","id":"glossary-7","chapter":"Glossary","heading":"Glossary","text":" \nTable 20: Glossary Week 9\n ","code":""},{"path":"flashcards-7.html","id":"flashcards-7","chapter":"Flashcards","heading":"Flashcards","text":"\n\n \n\n\n \n\n\n \n","code":""},{"path":"methods-methods-methods-2.html","id":"methods-methods-methods-2","chapter":"Methods, Methods, Methods","heading":"Methods, Methods, Methods","text":"sort covered create dummy variables already Week 2, completeness’ sake exploration create , include regression models, interpret (-important reference category…).Just last week working American National Election Studies (ANES), precise pilot survey conducted 2020 presidential election. haven’t already done , register ANES order download data set. , please follow link.","code":""},{"path":"methods-methods-methods-2.html","id":"data-prep-5","chapter":"Methods, Methods, Methods","heading":"Data Prep","text":"Place ANES data folder using working directory session. Open “Code Data Preparation” , copy RScript. Remember adjust working directory setwd() command beginning. run RScript ready proceed video.","code":"\n######################################\n# MMM - Week 9 - Dummy Variables\n######################################\n\n\n# Set WD\nsetwd()\n\n# Load packages\n\nlibrary(tidyverse)\n\n# Load data set\n\nanes <- read_csv(\"anes.csv\")\n\n# Get rid of missing values for variables used in analysis today\n\n## 999 is equivalent to NA, so needs to be recoded\nanes$fttrump1 <- with(anes, replace(fttrump1, fttrump1 == 999, NA)) \nanes$income <- with(anes, replace(income, income == 99, NA)) \n\nanes <- filter(anes, \n               !is.na(fttrump1),\n               !is.na(income))\n\n# Label variable `sex`\nanes$sex <- factor(anes$sex)\n\nanes <- anes %>% \n  mutate(sex=\n           recode(sex,\"1\"=\"Male\",\n                  \"2\"=\"Female\"))\n\nanes$sex <- as.factor(anes$sex)\n\n\n# Turn income variable into a numerical variable with mid-points of each level\n\nanes$income <- factor(anes$income)\n\nanes <- anes %>%\n  mutate(income_fac = recode(income,\n                             '1'= \"2500\",\n                             '2'= \"7499.5\",\n                             '3'= \"12499.5\",\n                             '4'= \"17499.5\",                       \n                             '5'= \"22499.5\",\n                             '6'= \"27499.5\",\n                             '7'= \"32499.5\",\n                             '8'= \"37499.5\",\n                             '9'= \"42499.5\",\n                             '10'= \"47499.5\",\n                             '11'= \"52499.5\",\n                             '12'= \"57499.5\",\n                             '13'= \"62499.5\",\n                             '14'= \"67499.5\",\n                             '15'= \"72499.5\",\n                             '16'= \"77499.5\",\n                             '17'= \"82499.5\",\n                             '18'= \"87499.5\",\n                             '19'= \"92499.5\",\n                             '20'= \"97499.5\",\n                             '21'= \"112499.5\",\n                             '22'= \"137499.5\",\n                             '23'= \"162499.5\",\n                             '24'= \"187499.5\",\n                             '25'= \"224999.5\",\n                             '26'= \"500000\"))\n\nanes$inc <- as.numeric(as.character(anes$income_fac))\n\n# save data set for use in video\n\nwrite.csv(anes, \"anes_week9.csv\")"},{"path":"methods-methods-methods-2.html","id":"video-and-rscript-5","chapter":"Methods, Methods, Methods","heading":"Video and RScript","text":"can find video introducing week’s method way worked example . can also access code typing video “Code Data Analysis” section. encourage type , though, code tends better sink depths brain 😉Dummy Variables R","code":"\n######################################\n# MMM - Week 9 - Dummy Variables\n######################################\n\n# Set WD\nsetwd()\n\n# Load packages\n\nlibrary(tidyverse)\n\n# Load data set\n\nanes <- read_csv(\"anes_week10.csv\")\nanes$sex <- as.factor(anes$sex)\n\n# Bivariate Regression\n############################\n\nmodel1 <- lm(fttrump1 ~ sex, data = anes)\n\nsummary(model1)\n\n\n\nanes <- anes %>%\n  mutate(sex = relevel(sex, ref = \"Male\"))\ntable(anes$sex)\n\n\n\nmodel2 <- lm(fttrump1 ~ sex, data = anes)\n\nsummary(model2)\n\n# Multiple Regression\n############################\n\nmodel3 <- lm(fttrump1 ~ inc + sex, data = anes)\n\nsummary(model3)"},{"path":"variable-transformations-and-exam-preparation.html","id":"variable-transformations-and-exam-preparation","chapter":"Variable Transformations and Exam Preparation","heading":"Variable Transformations and Exam Preparation","text":"","code":""},{"path":"variable-transformations-and-exam-preparation.html","id":"self-assessment-questions-5","chapter":"Variable Transformations and Exam Preparation","heading":"Self-Assessment Questions","text":"concept conditional expected value relate interpretation coefficients multiple regression?select variables multiple regression model?apply non-linear transformations variables?interpret effect logarithmized variable?Using data London wards (London Data Store, 2013) regression models Table 13 explain voter turnout 2012 mayoral elections.\ninterpret intercept Model 1\ninterpret slope coefficient Model 1\ninterpret slope coefficients Model 3\nexplain size effect slope coefficients Models 1 2 different\ninterpret model fit measure Model 3\ninterpret intercept Model 1interpret slope coefficient Model 1interpret slope coefficients Model 3explain size effect slope coefficients Models 1 2 differentinterpret model fit measure Model 3Table 13:  Regression Models Self-Reflection Exercises.Please stop don’t go beyond point compared notes answers.","code":""},{"path":"variable-transformations-and-exam-preparation.html","id":"exam-preparation","chapter":"Variable Transformations and Exam Preparation","heading":"Exam Preparation","text":"go solutions mock exam today. Please prepare exam note questions module content discuss.","code":""},{"path":"variable-transformations-and-exam-preparation.html","id":"exercises-5","chapter":"Variable Transformations and Exam Preparation","heading":"Exercises","text":"using crime.csv data set analyse attitudes experiences crime England Wales. dataset contains several variables relating questions asked experience perceptions crime representative sample along demographic details respondents. Data taken University Manchester, Cathie Marsh Institute Social Research (CMIST), UK Data Service, Office National Statistics (2019).","code":""},{"path":"variable-transformations-and-exam-preparation.html","id":"data-prep-6","chapter":"Variable Transformations and Exam Preparation","heading":"Data Prep","text":"respondent randomly assigned different module, indicated split asked subsection questions. antisocx variable part module asks score respondents much antisocial behaviour neighbourhood.Create new data set chosen ‘’ module. Call crime..","code":""},{"path":"variable-transformations-and-exam-preparation.html","id":"working-with-regression-analysis","chapter":"Variable Transformations and Exam Preparation","heading":"Working with Regression Analysis","text":"Previous research suggested men perceive antisocial behaviour urban areas rural areas.\nCreate linear model using male respondents crime.dependent variable antisocx independent variable rural2. findings support previous research?\nTest model using women. two models differ?\nUsing interaction effects test whether rural area larger effect women’s perception antisocial behaviour compared men’s?\ntest whether female effect perception higher antisocial behaviour urban compared rural areas?\nCreate linear model using male respondents crime.dependent variable antisocx independent variable rural2. findings support previous research?Test model using women. two models differ?Using interaction effects test whether rural area larger effect women’s perception antisocial behaviour compared men’s?test whether female effect perception higher antisocial behaviour urban compared rural areas?now using full crime data frame. wburgl variable asks respondents worried burgled answers ranging “worried” “worried” along “applicable” “Don’t know”.\nRecode “applicable” “Don’t know” NAs.\nUsing agegrp7 wburgl continuous variables, test hypothesis older people worried burgled.\nUsing dummy variable test whether 65 worried burglary younger.\nUsing dummies test whether age groups differ significantly youngest age group.\nintercept three models represent?\nRecode “applicable” “Don’t know” NAs.Using agegrp7 wburgl continuous variables, test hypothesis older people worried burgled.Using dummy variable test whether 65 worried burglary younger.Using dummies test whether age groups differ significantly youngest age group.intercept three models represent?","code":""},{"path":"variable-transformations-and-exam-preparation.html","id":"transformation-of-variables","chapter":"Variable Transformations and Exam Preparation","heading":"Transformation of Variables","text":"Section uses london_exercises.csv data set. already familiar data set Week 7. data taken London Data Store (2013).Unemployment rate, defined ratio people full time employment population working age often said related crime. Generate unemployment rate variable wards.theorised unemployment driving factor behind crime rates.\nPlot scatter graph unemployment rate, crime rate, regression line may used evaluate theory. Describe plot best fit line.\nPlot graph excluding wards crime rate greater 500. Describe plot best fit line.\nPlot another graph excluding wards crime rate 500 crime rate log transformed. Describe plot best fit line.\nBuild models. Interpret including effect size. model fits data better?\nPlot scatter graph unemployment rate, crime rate, regression line may used evaluate theory. Describe plot best fit line.Plot graph excluding wards crime rate greater 500. Describe plot best fit line.Plot another graph excluding wards crime rate 500 crime rate log transformed. Describe plot best fit line.Build models. Interpret including effect size. model fits data better?","code":""},{"path":"variable-transformations-and-exam-preparation.html","id":"going-further-2","chapter":"Variable Transformations and Exam Preparation","heading":"Going Further","text":"want little R, please return crime.csv data set .five variables ask worried respondent victim various crimes:\nCreate additive variable called worry variables score 0 indicates respondent answered “worried” score 15 indicates respondent answered “worried.” (Tip: Make sure clean variables NAs).\nmode, mean median worry?\nDescribe variable educat3. modified used continuous variable?\nUsing educat3 continuous factor variable evaluate statement “Worry victim crime higher lower education levels.”\n\\(R^2\\) values two models calculated? higher? make model better ?\nCalculate \\(97.5\\%\\) confidence intervals coefficients GCSEs Degrees. tell ?\nCreate additive variable called worry variables score 0 indicates respondent answered “worried” score 15 indicates respondent answered “worried.” (Tip: Make sure clean variables NAs).mode, mean median worry?Describe variable educat3. modified used continuous variable?Using educat3 continuous factor variable evaluate statement “Worry victim crime higher lower education levels.”\\(R^2\\) values two models calculated? higher? make model better ?Calculate \\(97.5\\%\\) confidence intervals coefficients GCSEs Degrees. tell ?","code":""},{"path":"homework.html","id":"homework","chapter":"Homework","heading":"Homework","text":"Work week’s flashcards familiarise relevant R functions.Find example NEW function apply R ensure worksPrepare exam January","code":""},{"path":"glossary-8.html","id":"glossary-8","chapter":"Glossary","heading":"Glossary","text":" \nTable 21: Glossary Week 10\n ","code":""},{"path":"flashcards-8.html","id":"flashcards-8","chapter":"Flashcards","heading":"Flashcards","text":"\n\n \n\n\n \n\n\n \n","code":""},{"path":"downloads.html","id":"downloads","chapter":"Downloads","heading":"Downloads","text":"Yes, solutions RScripts available without silly time restrictions. reason come realise operating module university, kindergarten. course, can download look solutions given exercises go first. means, cheat. can’t promise learn much. ’s choice.","code":""},{"path":"downloads.html","id":"documents","chapter":"Downloads","heading":"Documents","text":"PO91Q BibliographyStatistical TablesFormula CollectionWorksheet Week 3 SolutionsWorksheet Week 4 SolutionsWorksheet Week 5 SolutionsWorksheet Week 7 SolutionsWorksheet Week 8 SolutionsCase Study Week 8 Solutions","code":""},{"path":"downloads.html","id":"data-sets-in-alphabetical-order","chapter":"Downloads","heading":"Data Sets – in alphabetical order","text":"EU.xlsxExample.xlsxks2london_exercisesmortalityWDI_PO91Q.csv","code":""},{"path":"downloads.html","id":"r-scripts","chapter":"Downloads","heading":"R Scripts","text":"Week 2 SolutionsWeek 3 SolutionsWeek 4 SolutionsWeek 7 SolutionsWeek 8 Solutions","code":""},{"path":"glossary-9.html","id":"glossary-9","chapter":"Glossary","heading":"Glossary","text":"Unless otherwise noted, definitions taken Reiche (forthcoming).\nTable 22: Glossary PO91Q\n\nRelevance variables within broader theoretical empirical context research\n\nClear Theoretical Framework\n\n\nClear conceptualization\n\n\nExclusion alternative explanations\n\n\nClear Theoretical Framework\n\nClear conceptualization\n\nExclusion alternative explanations\n\nAsymmetry\n\nSignificant (sufficiently strong) statistical association\n","code":""},{"path":"list-of-references.html","id":"list-of-references","chapter":"List of References","heading":"List of References","text":"","code":""}]
